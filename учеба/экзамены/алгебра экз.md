### ====1. Матрицы. Основные понятия.

Матрицей называется прямоугольная таблица, составленная из чисел (или элементов некоторого поля, чаще всего $\mathbb{R}$ или $\mathbb{C}$), упорядоченных по строкам и столбцам. Формально, матрица размера $m\times n$ — это функция, сопоставляющая каждой паре индексов $(i,j)$, где $1\le i\le m$, $1\le j\le n$, элемент $a_{ij}$ из заданного множества.

Обозначается матрица заглавной латинской буквой (например, $A$), а её элементы — строчными с двойным индексом:  
$$
A=(a_{ij})_{m\times n}=
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n}\\
a_{21} & a_{22} & \cdots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix}
$$

#### Основные типы матриц:

1. **Квадратная матрица** — когда число строк равно числу столбцов: $m=n$. В этом случае число $n$ называется **порядком матрицы**.

2. **Нулевая матрица** $O$ — все элементы равны нулю: $a_{ij}=0$ для всех $i,j$.

3. **Диагональная матрица** — недиагональные элементы равны нулю: $a_{ij}=0$ при $i\ne j$. Пример:
   $$
   D=\operatorname{diag}(d_1,d_2,\dots,d_n)=
   \begin{pmatrix}
   d_1 & 0 & \cdots & 0\\
   0 & d_2 & \cdots & 0\\
   \vdots & \vdots & \ddots & \vdots\\
   0 & 0 & \cdots & d_n
   \end{pmatrix}
   $$

4. **Единичная матрица** $E$ (или $I$) — диагональная матрица, у которой все диагональные элементы равны 1: $e_{ii}=1$, $e_{ij}=0$ при $i\ne j$.

5. **Треугольные матрицы**:
   - **Верхнетреугольная**: $a_{ij}=0$ при $i>j$.
   - **Нижнетреугольная**: $a_{ij}=0$ при $i<j$.

6. **Симметричная матрица** — квадратная матрица, для которой $A=A^T$, то есть $a_{ij}=a_{ji}$ для всех $i,j$.

7. **Кососимметричная (антисимметричная) матрица** — квадратная матрица, удовлетворяющая условию $A^T=-A$, откуда следует $a_{ii}=0$ и $a_{ij}=-a_{ji}$.

8. **Транспонированная матрица** $A^T$ — матрица, полученная из $A$ заменой строк на столбцы: $(A^T)_{ij}=a_{ji}$. Свойства транспонирования:
   - $(A^T)^T = A$,
   - $(A+B)^T = A^T + B^T$,
   - $(AB)^T = B^T A^T$.

Матрицы впервые систематически изучались в XIX веке, в частности Артуром Кэли, который заложил основы матричного исчисления. Матричный аппарат стал фундаментальным инструментом в линейной алгебре, позволяя:
- компактно записывать и решать системы линейных уравнений,
- описывать линейные отображения между векторными пространствами,
- моделировать линейные преобразования (повороты, растяжения и т.п.) в геометрии и физике,
- применять в теории графов, экономике, машинном обучении и других областях.

Важно подчеркнуть, что матрица сама по себе — это не число, а **объект**, над которым определены операции: сложение, умножение на число, умножение матриц (при согласованных размерностях), нахождение определителя (только для квадратных матриц), обращение и др.

---
### ==2. Элементы комбинаторики.

Комбинаторика — раздел дискретной математики, посвящённый подсчёту количества различных способов составления, выбора или упорядочивания элементов конечных множеств при выполнении определённых условий. Она лежит в основе теории вероятностей, криптографии, теории информации и анализа алгоритмов.

#### Основные комбинаторные правила:

1. **Правило суммы**: если объект $A$ можно выбрать $m$ способами, а объект $B$ — $n$ способами, и эти выборы взаимно исключают друг друга, то выбор «либо $A$, либо $B$» возможен $m+n$ способами.

2. **Правило произведения**: если выбор объекта $A$ возможен $m$ способами, и для каждого такого выбора объект $B$ можно выбрать $n$ способами, то упорядоченную пару $(A,B)$ можно выбрать $m\cdot n$ способами.

Эти правила обобщаются на любое конечное число объектов.

#### Основные комбинаторные конфигурации:

##### 1. Перестановки

**Перестановкой** из $n$ различных элементов называется любой упорядоченный набор, содержащий все эти элементы ровно по одному разу. Число всех перестановок $n$ элементов обозначается $P_n$ и вычисляется как факториал:
$$
P_n = n! = 1\cdot 2\cdot 3\cdot \ldots \cdot n,\quad\text{причём }0!:=1.
$$

Пример: перестановки множества $\{1,2,3\}$ — это $(1,2,3)$, $(1,3,2)$, $(2,1,3)$, $(2,3,1)$, $(3,1,2)$, $(3,2,1)$: всего $3!=6$.

##### 2. Размещения

**Размещением** из $n$ элементов по $k$ (обозначается $A_n^k$ или $P(n,k)$) называется упорядоченный набор из $k$ различных элементов, выбранных из $n$-элементного множества.

Число размещений вычисляется по формуле:
$$
A_n^k = n(n-1)(n-2)\cdots(n-k+1) = \frac{n!}{(n-k)!}
$$

Если допускаются повторения элементов, то число **размещений с повторениями** равно $n^k$.

Пример: сколько трёхзначных чисел можно составить из цифр $\{1,2,3,4\}$ без повторений? Это $A_4^3 = 4\cdot3\cdot2 = 24$.

##### 3. Сочетания

**Сочетанием** из $n$ элементов по $k$ (обозначается $C_n^k$ или $\binom{n}{k}$) называется неупорядоченное подмножество из $k$ элементов, выбранных из $n$-элементного множества.

Число сочетаний:
$$
\binom{n}{k} = \frac{n!}{k!(n-k)!}
$$

Свойства биномиальных коэффициентов:
- $\binom{n}{k} = \binom{n}{n-k}$,
- $\binom{n}{0} = \binom{n}{n} = 1$,
- $\binom{n+1}{k} = \binom{n}{k-1} + \binom{n}{k}$ (треугольник Паскаля).

Если допускаются повторения элементов, число **сочетаний с повторениями** из $n$ по $k$ равно:
$$
\binom{n+k-1}{k}
$$

Пример: сколько способов выбрать 2 карты из колоды в 36 карт? Это $\binom{36}{2}=630$.

#### Применение:

- В теории вероятностей: подсчёт благоприятных и всех возможных исходов.
- В алгоритмах: оценка сложности переборных методов.
- В криптографии: оценка числа возможных ключей.
- В статистике: выборка без возвращения моделируется сочетаниями.

---
### ====3. Определитель матрицы. Вычисление определителей разных порядков.

**Определитель** (или **детерминант**) — числовая характеристика квадратной матрицы, играющая фундаментальную роль в линейной алгебре. Он обозначается $\det A$ или $|A|$ и используется для выявления вырожденности матрицы, решения систем линейных уравнений (метод Крамера), нахождения обратной матрицы и вычисления объёмов в геометрии.

#### Определение

Пусть $A=(a_{ij})$ — квадратная матрица порядка $n$. Определитель матрицы $A$ определяется рекуррентно:

- Для $n=1$: $\det A = a_{11}$.
- Для $n=2$:  
  $$
  \det\begin{pmatrix}a_{11}&a_{12}\\a_{21}&a_{22}\end{pmatrix}=a_{11}a_{22}-a_{12}a_{21}.
  $$
- Для $n\ge3$ — по формуле **разложения по строке или столбцу**:
  $$
  \det A = \sum_{j=1}^{n} a_{ij}A_{ij} \quad\text{(разложение по $i$-й строке)},
  $$
  $$
  \det A = \sum_{i=1}^{n} a_{ij}A_{ij} \quad\text{(разложение по $j$-му столбцу)},
  $$
  где $A_{ij}=(-1)^{i+j}M_{ij}$ — **алгебраическое дополнение** элемента $a_{ij}$, а $M_{ij}$ — **минор**, то есть определитель матрицы порядка $(n-1)$, полученной из $A$ вычёркиванием $i$-й строки и $j$-го столбца.

#### Определители низких порядков

- **Порядок 1**: $\det(a_{11}) = a_{11}$.
- **Порядок 2**:
  $$
  \det\begin{pmatrix}a&b\\c&d\end{pmatrix}=ad-bc.
  $$
- **Порядок 3** — часто вычисляется по **правилу Саррюса** (только для $3\times3$):
  $$
  \det\begin{pmatrix}
  a_{11}&a_{12}&a_{13}\\
  a_{21}&a_{22}&a_{23}\\
  a_{31}&a_{32}&a_{33}
  \end{pmatrix}
  = a_{11}a_{22}a_{33}+a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32}
  - a_{13}a_{22}a_{31}-a_{11}a_{23}a_{32}-a_{12}a_{21}a_{33}.
  $$

Однако правило Саррюса **не обобщается** на матрицы порядка выше 3. Для них применяется разложение по строке/столбцу или **метод приведения к треугольному виду**.

#### Свойства определителей

1. $\det A = \det A^T$.
2. Если поменять местами две строки (или два столбца), определитель изменит знак.
3. Если строка (столбец) состоит из нулей, то $\det A = 0$.
4. Если две строки (или два столбца) пропорциональны (или равны), то $\det A = 0$.
5. Определитель линейно зависит от каждой строки (столбца) в отдельности:
   $$
   \det(\dots,\alpha\mathbf{u}+\beta\mathbf{v},\dots) = \alpha\det(\dots,\mathbf{u},\dots) + \beta\det(\dots,\mathbf{v},\dots).
   $$
6. При умножении строки (столбца) на число $\lambda$, определитель умножается на $\lambda$.
7. Прибавление к одной строке другой, умноженной на число, **не изменяет** определитель.
8. $\det(AB) = \det A \cdot \det B$.
9. $\det(\lambda A) = \lambda^n \det A$ для матрицы порядка $n$.

#### Вычисление определителей высоких порядков

На практике для матриц порядка $n\ge4$ используют **метод элементарных преобразований**:
- Приводят матрицу к верхнетреугольному виду с помощью операций, не изменяющих определитель (или изменяющих его предсказуемо).
- Определитель треугольной матрицы равен произведению элементов главной диагонали:
  $$
  \det A = a_{11}a_{22}\cdots a_{nn}.
  $$

Пример:  
$$
A=\begin{pmatrix}
2&1&3\\
0&-1&4\\
0&0&5
\end{pmatrix}
\quad\Rightarrow\quad
\det A = 2\cdot(-1)\cdot5 = -10.
$$

Определитель равен нулю тогда и только тогда, когда строки (или столбцы) матрицы линейно зависимы. Это эквивалентно тому, что матрица **вырождена** (необратима).

---
### ==4. Обратная матрица, алгоритм нахождения.

**Обратной матрицей** к квадратной матрице $A$ порядка $n$ называется такая матрица $A^{-1}$, для которой выполняется:
$$
A A^{-1} = A^{-1} A = E,
$$
где $E$ — единичная матрица порядка $n$.

Обратная матрица существует **только для невырожденных матриц**, то есть таких, у которых $\det A \ne 0$. Если $\det A = 0$, матрица называется **вырожденной**, и обратной к ней не существует.

#### Алгоритм нахождения обратной матрицы

Существует несколько методов. Наиболее распространены:

##### 1. **Метод присоединённой (союзной) матрицы**

Этот метод основан на формуле:
$$
A^{-1} = \frac{1}{\det A} \cdot A^{\ast},
$$
где $A^{\ast}$ — **присоединённая (союзная) матрица**, составленная из алгебраических дополнений элементов исходной матрицы, транспонированная.

Шаги:
1. Вычислить $\det A$. Если $\det A = 0$, обратная матрица не существует.
2. Для каждого элемента $a_{ij}$ найти его алгебраическое дополнение:  
   $A_{ij} = (-1)^{i+j} M_{ij}$.
3. Составить матрицу из алгебраических дополнений: $(A_{ij})$.
4. Транспонировать её: $A^{\ast} = (A_{ji})$.
5. Разделить каждый элемент на $\det A$:
   $$
   A^{-1} = \frac{1}{\det A}
   \begin{pmatrix}
   A_{11} & A_{21} & \cdots & A_{n1}\\
   A_{12} & A_{22} & \cdots & A_{n2}\\
   \vdots & \vdots & \ddots & \vdots\\
   A_{1n} & A_{2n} & \cdots & A_{nn}
   \end{pmatrix}
   $$

Пример для $2\times2$:
$$
A=\begin{pmatrix}a&b\\c&d\end{pmatrix},\quad
\det A = ad-bc \ne 0,\quad
A^{-1} = \}.
$$

##### 2. **Метод элементарных преобразований (метод Гаусса–Жордана)**

Этот метод более эффективен для матриц порядка $n\ge3$.

Шаги:
1. Записать **присоединённую матрицу** $[A \mid E]$, где $E$ — единичная матрица того же порядка.
2. С помощью элементарных преобразований строк привести левую часть к единичной матрице.
3. В результате правая часть преобразуется в $A^{-1}$:
   $$
   [A \mid E] \xrightarrow{\text{строковые преобразования}} [E \mid A^{-1}].
   $$

Элементарные преобразования строк:
- перестановка двух строк;
- умножение строки на ненулевое число;
- прибавление к одной строке другой, умноженной на число.

Пример (кратко):
$$
\left[\begin{array}{cc|cc}
2 & 1 & 1 & 0\\
1 & 1 & 0 & 1
\end{array}\right]
\rightarrow
\left[\begin{array}{cc|cc}
1 & 0 & 1 & -1\\
0 & 1 & -1 & 2
\end{array}\right]
\Rightarrow
A^{-1} = \begin{pmatrix}1&-1\\-1&2\end{pmatrix}.
$$

#### Свойства обратной матрицы

- $(A^{-1})^{-1} = A$,
- $(AB)^{-1} = B^{-1}A^{-1}$,
- $(A^T)^{-1} = (A^{-1})^T$,
- $\det(A^{-1}) = \dfrac{1}{\det A}$.

Обратная матрица применяется:
- при решении систем вида $AX = B$: $X = A^{-1}B$,
- в линейных преобразованиях (переход к обратному отображению),
- в дифференциальной геометрии и физике (например, в теории упругости).

---
### ==5. Действия над матрицами.

Над матрицами определены следующие основные операции: **сложение**, **умножение на число**, **умножение матриц** и **транспонирование**. Все операции имеют строгие условия применимости, обусловленные размерностью матриц.

#### 1. Сложение матриц

Сложение определено только для матриц **одинаковой размерности** $m\times n$.  
Пусть $A=(a_{ij})$ и $B=(b_{ij})$ — матрицы размера $m\times n$. Их сумма — матрица $C=(c_{ij})$ того же размера, где  
$$
c_{ij} = a_{ij} + b_{ij} \quad \text{для всех } i=1,\dots,m;\ j=1,\dots,n.
$$

**Свойства сложения**:
- **Коммутативность**: $A + B = B + A$,
- **Ассоциативность**: $(A + B) + C = A + (B + C)$,
- **Существование нулевой матрицы**: $A + O = A$,
- **Существование противоположной матрицы**: $A + (-A) = O$.

#### 2. Умножение матрицы на число

Пусть $\lambda$ — скаляр (действительное или комплексное число), $A=(a_{ij})$ — матрица размера $m\times n$. Произведение $\lambda A$ — матрица $B=(b_{ij})$ той же размерности, где  
$$
b_{ij} = \lambda a_{ij}.
$$

**Свойства**:
- $\lambda(\mu A) = (\lambda\mu)A$,
- $(\lambda + \mu)A = \lambda A + \mu A$,
- $\lambda(A + B) = \lambda A + \lambda B$,
- $1\cdot A = A$.

Эти свойства показывают, что множество всех матриц размера $m\times n$ образует **векторное пространство** над полем $\mathbb{R}$ (или $\mathbb{C}$).

#### 3. Умножение матриц

Умножение матриц определено, если **число столбцов первой матрицы равно числу строк второй**.  
Пусть $A=(a_{ij})$ — матрица размера $m\times p$, $B=(b_{jk})$ — матрица размера $p\times n$. Тогда их произведение $C=AB$ — матрица размера $m\times n$, где  
$$
c_{ik} = \sum_{j=1}^{p} a_{ij} b_{jk}.
$$

Это означает, что элемент $c_{ik}$ — скалярное произведение $i$-й строки матрицы $A$ на $k$-й столбец матрицы $B$.

**Важные замечания**:
- Умножение матриц **не коммутативно**: в общем случае $AB \ne BA$.
- Даже если $AB$ и $BA$ определены, они могут быть разного размера или не равны.
- Пример некоммутативности:
  $$
  A=\begin{pmatrix}1&0\\0&0\end{pmatrix},\quad
  B=\begin{pmatrix}0&1\\0&0\end{pmatrix}
  \Rightarrow
  AB=\begin{pmatrix}0&1\\0&0\end{pmatrix},\quad
  BA=\begin{pmatrix}0&0\\0&0\end{pmatrix}.
  $$

**Свойства умножения**:
- **Ассоциативность**: $(AB)C = A(BC)$,
- **Дистрибутивность**: $A(B + C) = AB + AC$, $(A + B)C = AC + BC$,
- **Совместимость с умножением на скаляр**: $\lambda(AB) = (\lambda A)B = A(\lambda B)$,
- **Наличие единичной матрицы**: $AE = EA = A$ (если размерности согласованы).

#### 4. Транспонирование

Операция транспонирования превращает строки матрицы в столбцы.  
Если $A=(a_{ij})$ — матрица размера $m\times n$, то её транспонированная матрица $A^T$ — размера $n\times m$, где  
$$
(A^T)_{ij} = a_{ji}.
$$

**Свойства**:
- $(A^T)^T = A$,
- $(A + B)^T = A^T + B^T$,
- $(\lambda A)^T = \lambda A^T$,
- $(AB)^T = B^T A^T$.

#### Применение

Операции над матрицами лежат в основе:
- записи и решения систем линейных уравнений ($AX = B$),
- линейных преобразований векторных пространств,
- компьютерной графики (аффинные преобразования),
- теории цепей Маркова, экономических моделей (модель Леонтьева) и др.

---
### ==6. Элементарные преобразования матриц. Ранг матрицы и его вычисление.

#### Элементарные преобразования матриц

Элементарными преобразованиями строк (или столбцов) матрицы называются следующие операции:

1. **Перестановка двух строк** (или двух столбцов).
2. **Умножение строки** (или столбца) **на ненулевое число**.
3. **Прибавление к одной строке другой строки, умноженной на произвольное число** (аналогично для столбцов).

Эти преобразования не нарушают **линейные зависимости** между строками (или столбцами) и сохраняют **ранг** матрицы.

Две матрицы называются **эквивалентными**, если одна получается из другой конечной последовательностью элементарных преобразований. Обозначается: $A \sim B$.

#### Ранг матрицы

**Рангом матрицы** $A$ (обозначается $\operatorname{rank} A$ или $\operatorname{rg} A$) называется **максимальное число линейно независимых строк** (или, что эквивалентно, **столбцов**) матрицы. Это также равно **порядку наибольшего ненулевого минора** матрицы.

**Ключевые свойства ранга**:
- $\operatorname{rank} A = \operatorname{rank} A^T$,
- $\operatorname{rank} A \le \min(m,n)$ для матрицы размера $m\times n$,
- Ранг не изменяется при элементарных преобразованиях,
- $\operatorname{rank}(AB) \le \min(\operatorname{rank} A, \operatorname{rank} B)$,
- Если $A$ — квадратная матрица порядка $n$, то $\operatorname{rank} A = n$ тогда и только тогда, когда $\det A \ne 0$.

#### Методы вычисления ранга

##### 1. **Метод окаймляющих миноров**

- Находят ненулевой минор наименьшего порядка (например, $1\times1$).
- Последовательно «окаймляют» его, добавляя по одной строке и столбцу, и вычисляют миноры следующего порядка.
- Если все окаймляющие миноры порядка $r+1$ равны нулю, а минор порядка $r$ ненулевой, то $\operatorname{rank} A = r$.

##### 2. **Метод элементарных преобразований (основной метод)**

Приводят матрицу к **ступенчатому (треугольному) виду** с помощью элементарных преобразований строк. Ранг равен **числу ненулевых строк** в ступенчатой матрице.

**Ступенчатая форма** — матрица, в которой:
- Все нулевые строки, если есть, находятся внизу,
- В каждой ненулевой строке первый ненулевой элемент (ведущий) находится правее ведущего элемента предыдущей строки.

Пример:  
$$
A = \begin{pmatrix}
1 & 2 & 3\\
2 & 4 & 6\\
1 & 1 & 1
\end{pmatrix}
\ \xrightarrow{\text{элементарные преобразования}}\
\begin{pmatrix}
1 & 2 & 3\\
0 & -1 & -2\\
0 & 0 & 0
\end{pmatrix}
$$
В ступенчатой форме две ненулевые строки ⇒ $\operatorname{rank} A = 2$.

#### Геометрический и алгебраический смысл

- Ранг матрицы системы линейных уравнений определяет **размерность образа** линейного отображения, заданного этой матрицей.
- В системе $AX = B$ ранг основной матрицы и расширенной матрицы определяет **существование решений** (теорема Кронекера–Капелли).

---
### ==7. Арифметические $n$-мерные векторы над полем. Линейная зависимость и независимость систем арифметических векторов.

#### Арифметические $n$-мерные векторы

Пусть $\mathbb{F}$ — произвольное поле (чаще всего $\mathbb{R}$ или $\mathbb{C}$). **Арифметическим $n$-мерным вектором над полем $\mathbb{F}$** называется упорядоченный набор из $n$ элементов поля:
$$
\mathbf{a} = (a_1, a_2, \dots, a_n), \quad a_i \in \mathbb{F}.
$$

Множество всех таких векторов обозначается $\mathbb{F}^n$. Над векторами из $\mathbb{F}^n$ определены две операции:

1. **Сложение векторов**:  
   $$
   (a_1, \dots, a_n) + (b_1, \dots, b_n) = (a_1 + b_1, \dots, a_n + b_n).
   $$

2. **Умножение вектора на скаляр** $\lambda \in \mathbb{F}$:  
   $$
   \lambda(a_1, \dots, a_n) = (\lambda a_1, \dots, \lambda a_n).
   $$

Эти операции удовлетворяют аксиомам векторного (линейного) пространства, поэтому $\mathbb{F}^n$ является **$n$-мерным векторным пространством над полем $\mathbb{F}$**.

#### Линейная зависимость и независимость

Пусть дана система векторов $\mathbf{a}_1, \mathbf{a}_2, \dots, \mathbf{a}_k \in \mathbb{F}^n$.

**Определение**. Система векторов называется **линейно зависимой**, если существуют скаляры $\lambda_1, \dots, \lambda_k \in \mathbb{F}$, **не все равные нулю**, такие что:
$$
\lambda_1 \mathbf{a}_1 + \lambda_2 \mathbf{a}_2 + \dots + \lambda_k \mathbf{a}_k = \mathbf{0},
$$
где $\mathbf{0} = (0, 0, \dots, 0)$ — нулевой вектор.

Если указанное равенство возможно **только при** $\lambda_1 = \lambda_2 = \dots = \lambda_k = 0$, то система называется **линейно независимой**.

#### Критерии и свойства

- Любая система, содержащая **нулевой вектор**, линейно зависима.
- Система из **одного вектора** линейно зависима тогда и только тогда, когда этот вектор — нулевой.
- Если к линейно зависимой системе добавить любой вектор, она останется линейно зависимой.
- Если система векторов линейно независима, то **никакой из её векторов нельзя представить как линейную комбинацию остальных**.
- В пространстве $\mathbb{F}^n$ любая система из **более чем $n$ векторов** линейно зависима.

#### Связь с матрицами и рангом

Рассмотрим матрицу $A$, строки (или столбцы) которой — заданные векторы. Тогда:
- Система строк (или столбцов) линейно независима **тогда и только тогда**, когда $\operatorname{rank} A$ равен числу векторов.
- Максимальное число линейно независимых векторов в системе равно рангу соответствующей матрицы.

#### Пример

Векторы $\mathbf{a}_1 = (1,2,3)$, $\mathbf{a}_2 = (2,4,6)$ в $\mathbb{R}^3$ линейно зависимы, так как $\mathbf{a}_2 = 2\mathbf{a}_1$, или, эквивалентно, $2\mathbf{a}_1 - \mathbf{a}_2 = \mathbf{0}$.

Векторы $\mathbf{e}_1 = (1,0,0)$, $\mathbf{e}_2 = (0,1,0)$, $\mathbf{e}_3 = (0,0,1)$ — линейно независимы и образуют **стандартный базис** $\mathbb{R}^3$.

#### Значение понятия

Линейная (не)зависимость — ключевое понятие в линейной алгебре. Оно лежит в основе:
- определения **базиса** и **размерности** векторного пространства,
- анализа **разрешимости систем линейных уравнений**,
- построения **фундаментальной системы решений** однородных систем,
- теории **линейных операторов**.

---
### ==8. Системы линейных уравнений. Основные определения.

#### Общая запись системы

Системой $m$ линейных уравнений с $n$ неизвестными над полем $\mathbb{F}$ (обычно $\mathbb{R}$) называется совокупность уравнений вида:
$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1, \\
a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_2, \\
\quad\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n = b_m,
\end{cases}
$$
где:
- $x_1, x_2, \dots, x_n$ — **неизвестные**,
- $a_{ij} \in \mathbb{F}$ — **коэффициенты** при неизвестных,
- $b_i \in \mathbb{F}$ — **свободные члены**.

#### Матричная форма

Систему можно записать в компактной **матричной форме**:
$$
A\mathbf{x} = \mathbf{b},
$$
где:
- $A = (a_{ij})_{m\times n}$ — **основная матрица системы**,
- $\mathbf{x} = (x_1, x_2, \dots, x_n)^T$ — **вектор неизвестных**,
- $\mathbf{b} = (b_1, b_2, \dots, b_m)^T$ — **вектор свободных членов**.

#### Расширенная матрица

Матрица, полученная присоединением столбца свободных членов к основной матрице, называется **расширенной матрицей системы**:
$$
\widetilde{A} = [A \mid \mathbf{b}] =
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} & \vert & b_1 \\
a_{21} & a_{22} & \cdots & a_{2n} & \vert & b_2 \\
\vdots & \vdots & \ddots & \vdots & \vert & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn} & \vert & b_m
\end{pmatrix}.
$$

#### Классификация систем

1. **Совместная система** — имеет хотя бы одно решение.
2. **Несовместная система** — не имеет решений.
3. **Определённая система** — совместная система, имеющая **единственное** решение.
4. **Неопределённая система** — совместная система, имеющая **более одного** (на самом деле — бесконечно много) решений.

#### Однородные и неоднородные системы

- **Однородная система**: все $b_i = 0$, то есть $A\mathbf{x} = \mathbf{0}$.  
  Всегда совместна (имеет **тривиальное решение** $\mathbf{x} = \mathbf{0}$).  
  Нетривиальные решения существуют тогда и только тогда, когда $\operatorname{rank} A < n$.

- **Неоднородная система**: хотя бы один $b_i \ne 0$.

#### Эквивалентные системы

Две системы называются **эквивалентными**, если множества их решений совпадают. Элементарные преобразования строк расширенной матрицы (перестановка уравнений, умножение на ненулевое число, сложение уравнений) порождают эквивалентные системы.

#### Пример

Система:
$$
\begin{cases}
2x + 3y = 5, \\
4x + 6y = 10
\end{cases}
\quad\Rightarrow\quad
A = \begin{pmatrix}2&3\\4&6\end{pmatrix},\ 
\mathbf{b} = \begin{pmatrix}5\\10\end{pmatrix},\ 
\widetilde{A} = \begin{pmatrix}2&3&\vert&5\\4&6&\vert&10\end{pmatrix}.
$$
Второе уравнение — удвоенное первое ⇒ система совместна и неопределена.

#### Значение

Понимание структуры систем линейных уравнений — основа для применения методов их решения (Гаусса, Крамера, матричного), а также для анализа линейных моделей в физике, экономике, машинном обучении и других науках.

---
### ==9. Определители. Основные понятия.

Определитель (детерминант) — фундаментальное скалярное значение, сопоставляемое каждой квадратной матрице над полем (обычно $\mathbb{R}$ или $\mathbb{C}$). Он играет центральную роль в линейной алгебре, геометрии и анализе, отражая такие свойства, как **объём параллелепипеда**, **обратимость линейного оператора** и **существование единственного решения системы уравнений**.

#### Формальное определение

Пусть $A = (a_{ij})$ — квадратная матрица порядка $n$. Определитель матрицы $A$ — это число $\det A$, задаваемое одной из эквивалентных формулировок:

1. **Рекуррентное определение (разложение по строке/столбцу)**:  
   $$
   \det A = \sum_{j=1}^{n} a_{ij} A_{ij},
   $$
   где $A_{ij} = (-1)^{i+j} M_{ij}$ — алгебраическое дополнение, $M_{ij}$ — минор (определитель подматрицы, полученной вычёркиванием $i$-й строки и $j$-го столбца).

2. **Аксиоматическое определение**:  
   Определитель — единственная функция $D: M_n(\mathbb{F}) \to \mathbb{F}$, удовлетворяющая трём условиям:
   - **Полилинейность**: линейна по каждой строке при фиксированных остальных.
   - **Кососимметричность**: при перестановке двух строк знак меняется на противоположный.
   - **Нормировка**: $\det E = 1$, где $E$ — единичная матрица.

3. **Разложение по перестановкам (формула Лейбница)**:  
   $$
   \det A = \sum_{\sigma \in S_n} \operatorname{sgn}(\sigma) \cdot a_{1\sigma(1)} a_{2\sigma(2)} \cdots a_{n\sigma(n)},
   $$
   где $S_n$ — множество всех перестановок чисел $\{1,2,\dots,n\}$, $\operatorname{sgn}(\sigma)$ — знак перестановки ($+1$ для чётных, $-1$ для нечётных).

#### Геометрическая интерпретация

- Для $n=2$: $|\det A|$ равен **площади параллелограмма**, построенного на векторах-строках (или столбцах) матрицы.
- Для $n=3$: $|\det A|$ равен **объёму параллелепипеда**, натянутого на три вектора в $\mathbb{R}^3$.
- В общем случае: $|\det A|$ — **$n$-мерный объём** параллелепипеда, порождённого строками (или столбцами) матрицы.

Знак определителя указывает на **ориентацию** базиса: положительный — если ориентация совпадает со стандартной, отрицательный — если противоположна.

#### Основные свойства

1. $\det A = \det A^T$.
2. Если две строки (или столбца) равны или пропорциональны, то $\det A = 0$.
3. При перестановке двух строк $\det A$ меняет знак.
4. $\det(AB) = \det A \cdot \det B$.
5. $\det(\lambda A) = \lambda^n \det A$ для матрицы порядка $n$.
6. Если строка является суммой двух векторов, то определитель разлагается в сумму двух определителей.
7. Прибавление к строке другой строки, умноженной на число, **не меняет** определитель.
8. $\det A \ne 0$ тогда и только тогда, когда строки (столбцы) матрицы **линейно независимы**, то есть матрица **невырождена**.

#### Практическое значение

- Определитель используется в **методе Крамера** для решения систем линейных уравнений.
- Условие $\det A \ne 0$ эквивалентно **существованию обратной матрицы**.
- В дифференциальном исчислении определитель Якоби (якобиан) описывает локальное искажение объёма при замене переменных.
- В теории дифференциальных уравнений — для проверки линейной независимости решений (определитель Вронского).

---
### ==10. Метод Гаусса решения систем линейных уравнений.

**Метод Гаусса** (или метод последовательного исключения неизвестных) — классический и наиболее универсальный алгоритм решения систем линейных уравнений, основанный на приведении расширенной матрицы системы к **ступенчатому (треугольному) виду** с помощью элементарных преобразований строк.

#### Суть метода

Рассмотрим систему $A\mathbf{x} = \mathbf{b}$, где $A$ — матрица размера $m\times n$, $\mathbf{b} \in \mathbb{F}^m$.

1. **Прямой ход**:  
   С помощью элементарных преобразований строк расширенной матрицы $\widetilde{A} = [A \mid \mathbf{b}]$ добиваются, чтобы под каждым ведущим (первым ненулевым) элементом строки все элементы были нулевыми. В результате получают **ступенчатую матрицу**, например:
   $$
   \begin{pmatrix}
   a_{11} & a_{12} & a_{13} & \vert & b_1 \\
   0 & a_{22} & a_{23} & \vert & b_2 \\
   0 & 0 & 0 & \vert & b_3
   \end{pmatrix}.
   $$

2. **Анализ совместности**:  
   - Если в ступенчатой форме появляется строка вида $(0\ 0\ \dots\ 0 \mid c)$ при $c \ne 0$, система **несовместна**.
   - Иначе система **совместна**.

3. **Обратный ход**:  
   Начиная с последней ненулевой строки, последовательно выражают переменные через остальные. Если число ненулевых строк $r$ меньше числа неизвестных $n$, то $n - r$ переменных объявляются **свободными**, а остальные — **базисными (главными)**. Общее решение записывается в **параметрической форме**.

#### Пример

Решим систему:
$$
\begin{cases}
x + 2y + z = 3, \\
2x + 5y - z = -4, \\
3x - y + 2z = 5.
\end{cases}
$$

Расширенная матрица:
$$
\left[\begin{array}{ccc|c}
1 & 2 & 1 & 3\\
2 & 5 & -1 & -4\\
3 & -1 & 2 & 5
\end{array}\right]
\xrightarrow{\text{элементарные преобразования}}
\left[\begin{array}{ccc|c}
1 & 2 & 1 & 3\\
0 & 1 & -3 & -10\\
0 & 0 & 1 & 2
\end{array}\right].
$$

Обратный ход:
- $z = 2$,
- $y - 3z = -10 \Rightarrow y = -4$,
- $x + 2y + z = 3 \Rightarrow x = 9$.

Решение: $(x,y,z) = (9, -4, 2)$.

#### Преимущества метода Гаусса

- Применим к **любым системам** (совместным/несовместным, определённым/неопределённым, квадратным/прямоугольным).
- Не требует вычисления определителей (в отличие от метода Крамера), что делает его **вычислительно эффективным** даже для больших систем.
- Позволяет одновременно находить **ранг основной и расширенной матриц**, что необходимо для применения теоремы Кронекера–Капелли.

#### Модификации

- **Метод Жордана–Гаусса** (полное исключение): приводит матрицу к **приведённому ступенчатому виду** (единичная подматрица в левой части), сразу дающему решение.
- **Метод с выбором главного элемента**: для повышения **числовой устойчивости** на каждом шаге выбирают строку с максимальным по модулю ведущим элементом.

#### Применение

Метод Гаусса лежит в основе:
- решения линейных систем в вычислительной математике,
- нахождения обратной матрицы,
- вычисления ранга матрицы,
- построения базиса векторного пространства.

---
### ==11. Критерий совместности систем линейных уравнений.

**Критерий совместности** системы линейных уравнений устанавливает необходимое и достаточное условие существования хотя бы одного решения. Этот критерий сформулирован в **теореме Кронекера–Капелли**.

#### Формулировка теоремы Кронекера–Капелли

Система линейных уравнений  
$$
A\mathbf{x} = \mathbf{b}
$$  
совместна **тогда и только тогда**, когда **ранг основной матрицы системы равен рангу её расширенной матрицы**, то есть  
$$
\operatorname{rank} A = \operatorname{rank} \widetilde{A},
$$  
где $\widetilde{A} = [A \mid \mathbf{b}]$ — расширенная матрица, полученная присоединением столбца свободных членов $\mathbf{b}$ к основной матрице $A$.

#### Пояснение и доказательство (идея)

- **Необходимость**: если система совместна, то $\mathbf{b}$ является линейной комбинацией столбцов матрицы $A$ (поскольку $A\mathbf{x} = \mathbf{b}$ по определению означает, что $\mathbf{b} = x_1\mathbf{a}_1 + \dots + x_n\mathbf{a}_n$). Следовательно, добавление $\mathbf{b}$ к системе столбцов $A$ не увеличивает их линейную оболочку, а значит, не увеличивает ранг.
- **Достаточность**: если $\operatorname{rank} A = \operatorname{rank} \widetilde{A} = r$, то столбец $\mathbf{b}$ лежит в линейной оболочке столбцов матрицы $A$, и, значит, существует набор коэффициентов $x_1,\dots,x_n$, дающий $\mathbf{b}$ как их линейную комбинацию — то есть система имеет решение.

#### Следствия

1. Если $\operatorname{rank} A \ne \operatorname{rank} \widetilde{A}$, система **несовместна** (решений нет).
2. Если система совместна и $\operatorname{rank} A = n$ (где $n$ — число неизвестных), то система **определённая** (имеет единственное решение).
3. Если система совместна и $\operatorname{rank} A = r < n$, то система **неопределённая**, и множество решений зависит от $n - r$ свободных параметров.

#### Пример

Рассмотрим систему:
$$
\begin{cases}
x + y = 2, \\
2x + 2y = 5.
\end{cases}
$$

Основная и расширенная матрицы:
$$
A = \begin{pmatrix}1 & 1\\ 2 & 2\end{pmatrix}, \quad
\widetilde{A} = \begin{pmatrix}1 & 1 & \vert & 2\\ 2 & 2 & \vert & 5\end{pmatrix}.
$$

$\operatorname{rank} A = 1$, но после преобразований $\widetilde{A} \to \begin{pmatrix}1 & 1 & \vert & 2\\ 0 & 0 & \vert & 1\end{pmatrix}$, откуда $\operatorname{rank} \widetilde{A} = 2$.  
Поскольку ранги не равны, система **несовместна**.

#### Практическое применение

Теорема Кронекера–Капелли используется:
- как **первый шаг** при анализе любой системы линейных уравнений,
- для **обоснования** результатов метода Гаусса,
- в теории линейных операторов и функциональном анализе (в обобщённых формах).
---
### ==12. Метод Крамера решения систем линейных уравнений.

**Метод Крамера** — способ нахождения единственного решения **квадратной системы линейных уравнений** при условии, что её основная матрица **невырождена** (то есть её определитель отличен от нуля).

#### Формулировка

Рассмотрим систему $n$ линейных уравнений с $n$ неизвестными:
$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1, \\
a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_2, \\
\quad\vdots \\
a_{n1}x_1 + a_{n2}x_2 + \dots + a_{nn}x_n = b_n.
\end{cases}
$$

Обозначим:
- $\Delta = \det A$ — определитель **основной матрицы** $A = (a_{ij})$,
- $\Delta_i$ — определитель матрицы, полученной из $A$ заменой $i$-го столбца на столбец свободных членов $\mathbf{b} = (b_1, \dots, b_n)^T$.

**Теорема Крамера**:  
Если $\Delta \ne 0$, то система имеет **единственное решение**, и оно определяется формулами:
$$
x_i = \frac{\Delta_i}{\Delta}, \quad i = 1, 2, \dots, n.
$$

#### Пример

Решим систему:
$$
\begin{cases}
2x + y = 5, \\
x - 3y = -1.
\end{cases}
$$

Основная матрица и её определитель:
$$
A = \begin{pmatrix}2 & 1\\ 1 & -3\end{pmatrix}, \quad \Delta = \det A = 2\cdot(-3) - 1\cdot1 = -7 \ne 0.
$$

Определители для переменных:
$$
\Delta_1 = \det\begin{pmatrix}5 & 1\\ -1 & -3\end{pmatrix} = 5\cdot(-3) - 1\cdot(-1) = -14, \\
\Delta_2 = \det\begin{pmatrix}2 & 5\\ 1 & -1\end{pmatrix} = 2\cdot(-1) - 5\cdot1 = -7.
$$

Решение:
$$
x = \frac{\Delta_1}{\Delta} = \frac{-14}{-7} = 2, \quad
y = \frac{\Delta_2}{\Delta} = \frac{-7}{-7} = 1.
$$

#### Условия применимости

Метод Крамера **применим только** если:
1. Система **квадратная** ($n$ уравнений, $n$ неизвестных),
2. $\det A \ne 0$ (матрица невырождена).

Если $\det A = 0$, то:
- либо система **несовместна**,
- либо имеет **бесконечно много решений**,  
и метод Крамера **неприменим**.

#### Преимущества и недостатки

**Преимущества**:
- даёт **явные формулы** для каждого неизвестного,
- удобен при **теоретическом анализе** (например, в доказательствах),
- легко запоминается и применяется для малых $n$ (обычно $n \le 3$).

**Недостатки**:
- **Вычислительно неэффективен** при больших $n$: требует вычисления $n+1$ определителей порядка $n$, что при больших $n$ гораздо сложнее, чем метод Гаусса.
- Не применим к **прямоугольным системам** и к системам с $\det A = 0$.

#### Связь с другими понятиями

- Формулы Крамера следуют из **матричного метода**: если $A^{-1}$ существует, то $\mathbf{x} = A^{-1}\mathbf{b}$, а элементы $A^{-1}$ выражаются через алгебраические дополнения, что и приводит к частным $\Delta_i/\Delta$.
- В геометрии формулы Крамера интерпретируются как **отношения объёмов**: $x_i$ — это отношение объёма параллелепипеда, построенного на заменённом базисе, к объёму исходного.

---
### ==13. Решение невырожденных линейных систем. Формулы Крамера.

**Невырожденной линейной системой** называется квадратная система линейных уравнений $A\mathbf{x} = \mathbf{b}$, у которой основная матрица $A$ порядка $n$ удовлетворяет условию $\det A \ne 0$. Такая матрица называется **обратимой** или **невырожденной**, а сама система — **совместной и определённой**, то есть имеет **единственное решение**.

#### Существование и единственность решения

Если $\det A \ne 0$, то:
- строки и столбцы матрицы $A$ линейно независимы,
- линейное отображение $\mathbf{x} \mapsto A\mathbf{x}$ биективно,
- обратная матрица $A^{-1}$ существует,
- система $A\mathbf{x} = \mathbf{b}$ имеет **ровно одно** решение для любого вектора $\mathbf{b} \in \mathbb{F}^n$.

#### Формулы Крамера

Решение такой системы может быть записано в явном виде с помощью **формул Крамера**. Пусть:

- $\Delta = \det A$ — определитель основной матрицы,
- $\Delta_i = \det A_i$ — определитель матрицы $A_i$, полученной из $A$ заменой её $i$-го столбца на столбец свободных членов $\mathbf{b} = (b_1, \dots, b_n)^T$.

Тогда компоненты единственного решения даются формулами:
$$
x_i = \frac{\Delta_i}{\Delta}, \quad i = 1, 2, \dots, n.
$$

#### Вывод формул (кратко)

Рассмотрим матричное уравнение $A\mathbf{x} = \mathbf{b}$. Умножая обе части слева на $A^{-1}$, получаем:
$$
\mathbf{x} = A^{-1}\mathbf{b}.
$$

Известно, что $A^{-1} = \dfrac{1}{\det A} A^{\ast}$, где $A^{\ast}$ — присоединённая матрица, составленная из алгебраических дополнений и транспонированная. Тогда:
$$
x_i = \frac{1}{\det A} \sum_{j=1}^{n} A_{ji} b_j,
$$
где $A_{ji}$ — алгебраическое дополнение элемента $a_{ji}$. Но правая часть — это разложение определителя $\Delta_i$ по $i$-му столбцу, следовательно:
$$
x_i = \frac{\Delta_i}{\Delta}.
$$

#### Пример

Решим систему:
$$
\begin{cases}
3x + 2y = 7, \\
x - y = 1.
\end{cases}
$$

Матрица $A = \begin{pmatrix}3&2\\1&-1\end{pmatrix}$, $\Delta = \det A = -3 - 2 = -5 \ne 0$.

$$
\Delta_1 = \det\begin{pmatrix}7&2\\1&-1\end{pmatrix} = -7 - 2 = -9, \quad
\Delta_2 = \det\begin{pmatrix}3&7\\1&1\end{pmatrix} = 3 - 7 = -4.
$$

Тогда:
$$
x = \frac{\Delta_1}{\Delta} = \frac{-9}{-5} = \frac{9}{5}, \quad
y = \frac{\Delta_2}{\Delta} = \frac{-4}{-5} = \frac{4}{5}.
$$

Проверка: $3\cdot\frac{9}{5} + 2\cdot\frac{4}{5} = \frac{27+8}{5} = 7$, верно.

#### Особенности и ограничения

- Формулы Крамера применимы **только** к квадратным системам с $\det A \ne 0$.
- При $n \ge 4$ вычисление $n+1$ определителей становится **трудоёмким**, и предпочтительнее использовать метод Гаусса.
- Тем не менее, формулы Крамера важны в **теоретическом анализе**, особенно при исследовании зависимости решения от параметров системы.

#### Геометрическая интерпретация

В $\mathbb{R}^n$ величина $|\Delta|$ пропорциональна $n$-мерному объёму параллелепипеда, натянутого на векторы-столбцы матрицы $A$. Тогда $|x_i| = |\Delta_i|/|\Delta|$ можно трактовать как **относительный вклад** $i$-го направления в формирование вектора $\mathbf{b}$.

---
### ==14. Геометрический смысл смешанного, векторного и скалярного произведения векторов.

Скалярное, векторное и смешанное произведения — три фундаментальные операции над векторами в трёхмерном евклидовом пространстве $\mathbb{R}^3$, каждая из которых имеет ясный **геометрический смысл**.

#### 1. Скалярное произведение

Для векторов $\mathbf{a}, \mathbf{b} \in \mathbb{R}^n$ скалярное произведение определяется как:
$$
\mathbf{a} \cdot \mathbf{b} = a_1 b_1 + a_2 b_2 + \dots + a_n b_n.
$$

В $\mathbb{R}^3$ (и $\mathbb{R}^2$) оно также выражается через длины векторов и угол $\varphi$ между ними:
$$
\mathbf{a} \cdot \mathbf{b} = \|\mathbf{a}\| \|\mathbf{b}\| \cos\varphi.
$$

**Геометрический смысл**:
- Скалярное произведение равно **произведению длины одного вектора на длину проекции второго вектора на направление первого**.
- Если $\mathbf{a} \cdot \mathbf{b} = 0$, векторы **ортогональны** (перпендикулярны).
- Знак произведения указывает на остроту угла:  
  - $\mathbf{a} \cdot \mathbf{b} > 0$ ⇔ $\varphi < 90^\circ$,  
  - $\mathbf{a} \cdot \mathbf{b} < 0$ ⇔ $\varphi > 90^\circ$.

#### 2. Векторное произведение

Определено **только в $\mathbb{R}^3$**. Для $\mathbf{a} = (a_1,a_2,a_3)$, $\mathbf{b} = (b_1,b_2,b_3)$ векторное произведение:
$$
\mathbf{a} \times \mathbf{b} =
\begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
a_1 & a_2 & a_3 \\
b_1 & b_2 & b_3
\end{vmatrix}
= (a_2b_3 - a_3b_2,\ a_3b_1 - a_1b_3,\ a_1b_2 - a_2b_1).
$$

**Геометрический смысл**:
- Вектор $\mathbf{a} \times \mathbf{b}$ **перпендикулярен** обоим векторам $\mathbf{a}$ и $\mathbf{b}$.
- Его направление определяется **правилом правой руки**.
- Длина вектора равна **площади параллелограмма**, построенного на $\mathbf{a}$ и $\mathbf{b}$:
  $$
  \|\mathbf{a} \times \mathbf{b}\| = \|\mathbf{a}\| \|\mathbf{b}\| \sin\varphi.
  $$
- Если $\mathbf{a} \times \mathbf{b} = \mathbf{0}$, векторы **коллинеарны**.

#### 3. Смешанное произведение

Смешанное (или скалярно-векторное) произведение трёх векторов $\mathbf{a}, \mathbf{b}, \mathbf{c} \in \mathbb{R}^3$ определяется как:
$$
(\mathbf{a}, \mathbf{b}, \mathbf{c}) = \mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}).
$$

Оно равно определителю, составленному из координат векторов:
$$
(\mathbf{a}, \mathbf{b}, \mathbf{c}) =
\begin{vmatrix}
a_1 & a_2 & a_3 \\
b_1 & b_2 & b_3 \\
c_1 & c_2 & c_3
\end{vmatrix}.
$$

**Геометрический смысл**:
- Абсолютное значение смешанного произведения равно **объёму параллелепипеда**, построенного на векторах $\mathbf{a}, \mathbf{b}, \mathbf{c}$.
- Знак указывает на **ориентацию тройки векторов**:
  - Положительный — если тройка **правая** (соответствует ориентации $\mathbf{i},\mathbf{j},\mathbf{k}$),
  - Отрицательный — если **левая**.
- Если $(\mathbf{a}, \mathbf{b}, \mathbf{c}) = 0$, векторы **компланарны** (лежат в одной плоскости).

#### Связь между произведениями

- Скалярное произведение — **скаляр**, измеряет «согласованность направлений».
- Векторное произведение — **вектор**, измеряет «перпендикулярное направление» и площадь.
- Смешанное произведение — **скаляр**, измеряет объём и ориентацию.

Эти операции широко используются в физике (работа, момент силы, поток), компьютерной графике (нормали, объёмы), механике и дифференциальной геометрии.

---
### ==15. Невырожденные матрицы. Основные понятия.

**Невырожденной** (или **неособенной**, **обратимой**) называется квадратная матрица $A$ порядка $n$ над полем $\mathbb{F}$ (обычно $\mathbb{R}$ или $\mathbb{C}$), для которой существует такая матрица $A^{-1}$ того же порядка, что  
$$
A A^{-1} = A^{-1} A = E,
$$  
где $E$ — единичная матрица порядка $n$.

#### Эквивалентные условия невырожденности

Для квадратной матрицы $A$ следующие утверждения **эквивалентны** (то есть выполняются одновременно):

1. $\det A \ne 0$.
2. Существует обратная матрица $A^{-1}$.
3. Строки (и столбцы) матрицы $A$ **линейно независимы**.
4. $\operatorname{rank} A = n$ (полный ранг).
5. Однородная система $A\mathbf{x} = \mathbf{0}$ имеет **только тривиальное решение** $\mathbf{x} = \mathbf{0}$.
6. Неоднородная система $A\mathbf{x} = \mathbf{b}$ имеет **единственное решение** для любого $\mathbf{b} \in \mathbb{F}^n$.
7. Линейное отображение $\mathbf{x} \mapsto A\mathbf{x}$ является **биекцией** (взаимно однозначным и сюръективным).
8. Все собственные значения матрицы $A$ **отличны от нуля**.

Эти эквивалентности образуют фундаментальную связь между алгебраическими, геометрическими и аналитическими свойствами матрицы.

#### Свойства невырожденных матриц

- Если $A$ и $B$ — невырожденные матрицы одного порядка, то:
  - $AB$ — невырожденная,
  - $(AB)^{-1} = B^{-1} A^{-1}$,
  - $(A^{-1})^{-1} = A$,
  - $(A^T)^{-1} = (A^{-1})^T$,
  - $\det(A^{-1}) = \dfrac{1}{\det A}$.

- Множество всех невырожденных матриц порядка $n$ над полем $\mathbb{F}$ образует группу относительно умножения — **общую линейную группу**, обозначаемую $GL(n, \mathbb{F})$.

#### Примеры

- Единичная матрица $E$ — невырожденная: $\det E = 1 \ne 0$, $E^{-1} = E$.
- Матрица $A = \begin{pmatrix}1 & 2\\ 3 & 4\end{pmatrix}$: $\det A = -2 \ne 0$ ⇒ невырожденная.
- Матрица $B = \begin{pmatrix}1 & 2\\ 2 & 4\end{pmatrix}$: $\det B = 0$ ⇒ **вырожденная**.

#### Практическое значение

Невырожденные матрицы играют ключевую роль в:
- решении систем линейных уравнений (методы Крамера, матричный),
- теории линейных преобразований (обратимость отображения),
- дифференциальных уравнениях (фундаментальная матрица решений),
- численных методах (обусловленность систем).

---
### ==16. Матричный метод решения систем линейных уравнений.

**Матричный метод** — способ решения квадратных систем линейных уравнений, основанный на использовании **обратной матрицы**.

#### Постановка задачи

Рассмотрим систему $n$ линейных уравнений с $n$ неизвестными:
$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1, \\
a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_2, \\
\quad\vdots \\
a_{n1}x_1 + a_{n2}x_2 + \dots + a_{nn}x_n = b_n.
\end{cases}
$$

В матричной форме система записывается как:
$$
A\mathbf{x} = \mathbf{b},
$$
где:
- $A = (a_{ij})$ — квадратная **основная матрица** порядка $n$,
- $\mathbf{x} = (x_1, x_2, \dots, x_n)^T$ — **вектор неизвестных**,
- $\mathbf{b} = (b_1, b_2, \dots, b_n)^T$ — **вектор свободных членов**.

#### Условие применимости

Матричный метод применим **только если матрица $A$ невырождена**, то есть $\det A \ne 0$. В этом случае существует обратная матрица $A^{-1}$.

#### Алгоритм решения

1. Убедиться, что $\det A \ne 0$.
2. Найти обратную матрицу $A^{-1}$ (например, методом присоединённой матрицы или Гаусса–Жордана).
3. Умножить обе части уравнения $A\mathbf{x} = \mathbf{b}$ слева на $A^{-1}$:
   $$
   A^{-1}(A\mathbf{x}) = A^{-1}\mathbf{b} \quad\Rightarrow\quad (A^{-1}A)\mathbf{x} = A^{-1}\mathbf{b} \quad\Rightarrow\quad E\mathbf{x} = A^{-1}\mathbf{b}.
   $$
4. Получаем **единственное решение**:
   $$
   \mathbf{x} = A^{-1}\mathbf{b}.
   $$

#### Пример

Решим систему:
$$
\begin{cases}
2x + y = 3, \\
x - y = 0.
\end{cases}
$$

Матрицы:
$$
A = \begin{pmatrix}2 & 1\\ 1 & -1\end{pmatrix}, \quad
\mathbf{b} = \begin{pmatrix}3\\ 0\end{pmatrix}.
$$

$\det A = -2 - 1 = -3 \ne 0$ ⇒ обратная существует.

Обратная матрица:
$$
A^{-1} = \frac{1}{-3} \begin{pmatrix}-1 & -1\\ -1 & 2\end{pmatrix}
= \begin{pmatrix}\frac{1}{3} & \frac{1}{3}\\ \frac{1}{3} & -\frac{2}{3}\end{pmatrix}.
$$

Решение:
$$
\mathbf{x} = A^{-1}\mathbf{b} =
\begin{pmatrix}\frac{1}{3} & \frac{1}{3}\\ \frac{1}{3} & -\frac{2}{3}\end{pmatrix}
\begin{pmatrix}3\\ 0\end{pmatrix}
= \begin{pmatrix}1\\ 1\end{pmatrix}.
$$

Проверка: $2\cdot1 + 1 = 3$, $1 - 1 = 0$ — верно.

#### Сравнение с другими методами

| Метод | Преимущества | Недостатки |
|------|---------------|------------|
| **Матричный** | Даёт компактную форму решения $\mathbf{x} = A^{-1}\mathbf{b}$; удобен при многократном решении с разными $\mathbf{b}$ | Требует вычисления всей обратной матрицы, что дороже, чем однократное решение методом Гаусса |
| **Крамера** | Явные формулы для каждого $x_i$ | Очень трудоёмок при $n \ge 4$ |
| **Гаусса** | Универсален, эффективен, работает с прямоугольными системами | Не даёт аналитического выражения решения |

#### Практическое применение

Матричный метод особенно полезен:
- в теоретических задачах (например, анализ зависимости решения от параметров),
- при решении **серии систем** с одной и той же матрицей $A$, но разными $\mathbf{b}$ (тогда $A^{-1}$ вычисляется один раз),
- в компьютерной алгебре и численных пакетах (например, в MATLAB оператор `\` реализует решение без явного обращения, но концептуально близок к матричному подходу).

---
### ==17. Однородная система линейных уравнений, условие существования ненулевых решений.

**Однородной системой линейных уравнений** называется система вида  
$$
A\mathbf{x} = \mathbf{0},
$$  
где $A$ — матрица размера $m\times n$ над полем $\mathbb{F}$, $\mathbf{x} = (x_1,\dots,x_n)^T$ — вектор неизвестных, $\mathbf{0} = (0,\dots,0)^T$ — нулевой вектор.

#### Основные свойства

1. **Всегда совместна**: тривиальное решение $\mathbf{x} = \mathbf{0}$ всегда существует.
2. **Множество решений образует подпространство**: если $\mathbf{x}_1$ и $\mathbf{x}_2$ — решения, то любая их линейная комбинация $\alpha\mathbf{x}_1 + \beta\mathbf{x}_2$ также является решением. Это подпространство называется **нуль-пространством** (или **ядром**) матрицы $A$ и обозначается $\ker A$.
3. **Размерность пространства решений**: если $\operatorname{rank} A = r$, то размерность $\ker A$ равна $n - r$ (теорема о ранге и дефекте).

#### Условие существования ненулевых решений

Однородная система имеет **ненулевые (нетривиальные) решения тогда и только тогда**, когда  
$$
\operatorname{rank} A < n,
$$  
то есть когда **столбцы матрицы $A$ линейно зависимы**.

В случае **квадратной матрицы** $A$ порядка $n$ это условие эквивалентно:  
$$
\det A = 0.
$$

#### Обоснование

- Если $\operatorname{rank} A = n$, то все столбцы линейно независимы, и уравнение $A\mathbf{x} = \mathbf{0}$ имеет только тривиальное решение.
- Если $\operatorname{rank} A = r < n$, то в системе после приведения к ступенчатому виду будет $n - r > 0$ свободных переменных, которые можно задавать произвольно, получая бесконечно много решений.

#### Фундаментальная система решений (ФСР)

Если $\dim(\ker A) = n - r = k > 0$, то существует **базис** этого подпространства — набор из $k$ линейно независимых решений $\mathbf{e}_1, \dots, \mathbf{e}_k$, такой что **любое решение** системы представляется в виде:
$$
\mathbf{x} = c_1\mathbf{e}_1 + c_2\mathbf{e}_2 + \dots + c_k\mathbf{e}_k, \quad c_i \in \mathbb{F}.
$$
Такой набор называется **фундаментальной системой решений**.

#### Пример

Рассмотрим систему:
$$
\begin{cases}
x + y + z = 0, \\
2x + 2y + 2z = 0.
\end{cases}
$$

Матрица $A = \begin{pmatrix}1&1&1\\2&2&2\end{pmatrix}$, $\operatorname{rank} A = 1 < 3$.  
Следовательно, существуют ненулевые решения.

Приведём к ступенчатому виду: $x + y + z = 0$. Возьмём $y = s$, $z = t$ — свободные переменные. Тогда $x = -s - t$.

Общее решение:
$$
\mathbf{x} = s\begin{pmatrix}-1\\1\\0\end{pmatrix} + t\begin{pmatrix}-1\\0\\1\end{pmatrix}.
$$

ФСР: $\left\{ \begin{pmatrix}-1\\1\\0\end{pmatrix}, \begin{pmatrix}-1\\0\\1\end{pmatrix} \right\}$.

#### Применение

- В теории дифференциальных уравнений: общее решение однородного линейного дифференциального уравнения строится аналогично ФСР.
- В линейной алгебре: ядро матрицы — ключевое понятие при изучении линейных отображений.
- В машинном обучении: нуль-пространство используется при анализе избыточности признаков.

---
### ==18. Решение невырожденных линейных систем. Формулы Крамера.

**Невырожденной линейной системой** называется квадратная система $n$ линейных уравнений с $n$ неизвестными, основная матрица $A$ которой удовлетворяет условию $\det A \ne 0$. Такая система всегда **совместна и определена**, то есть имеет **единственное решение**.

#### Общая запись системы

$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1, \\
a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_2, \\
\quad\vdots \\
a_{n1}x_1 + a_{n2}x_2 + \dots + a_{nn}x_n = b_n.
\end{cases}
$$

Обозначим:
- $$
- \Delta = \det A = \begin{vmatrix}
a_{11} & \cdots & a_{1n} \\
\vdots & \ddots & \vdots \\
a_{n1} & \cdots & a_{nn}
\end{vmatrix}
$$ — определитель основной матрицы,
- $$\Delta_i = \begin{vmatrix}
a_{11} & \cdots & b_1 & \cdots & a_{1n} \\
\vdots & \ddots & \vdots & \ddots & \vdots \\
a_{n1} & \cdots & b_n & \cdots & a_{nn}
\end{vmatrix}
$$ — определитель, полученный заменой $i$-го столбца на столбец свободных членов $\mathbf{b} = (b_1,\dots,b_n)^T$.

#### Формулы Крамера

Если $\Delta \ne 0$, то единственное решение системы даётся формулами:
$$
x_i = \frac{\Delta_i}{\Delta}, \quad i = 1, 2, \dots, n.
$$

#### Обоснование

Поскольку $\det A \ne 0$, матрица $A$ обратима, и решение может быть записано как $\mathbf{x} = A^{-1}\mathbf{b}$. Элементы обратной матрицы выражаются через алгебраические дополнения:
$$
(A^{-1})_{ij} = \frac{A_{ji}}{\det A},
$$
где $A_{ji}$ — алгебраическое дополнение элемента $a_{ji}$. Тогда:
$$
x_i = \sum_{j=1}^{n} (A^{-1})_{ij} b_j = \frac{1}{\det A} \sum_{j=1}^{n} A_{ji} b_j.
$$
Но сумма $\sum_{j=1}^{n} A_{ji} b_j$ — это разложение определителя $\Delta_i$ по $i$-му столбцу. Следовательно, $x_i = \Delta_i / \Delta$.

#### Пример

Система:
$$
\begin{cases}
x + 2y = 4, \\
3x - y = 5.
\end{cases}
$$

$\Delta = \begin{vmatrix}1 & 2\\ 3 & -1\end{vmatrix} = -1 - 6 = -7 \ne 0$.

$\Delta_1 = \begin{vmatrix}4 & 2\\ 5 & -1\end{vmatrix} = -4 - 10 = -14$,  
$\Delta_2 = \begin{vmatrix}1 & 4\\ 3 & 5\end{vmatrix} = 5 - 12 = -7$.

Решение:
$$
x = \frac{-14}{-7} = 2, \quad y = \frac{-7}{-7} = 1.
$$

#### Условия применимости и ограничения

- Применим **только к квадратным системам**.
- Требует $\det A \ne 0$.
- При $n \ge 4$ становится **вычислительно неэффективным** по сравнению с методом Гаусса.
- Однако даёт **аналитическое выражение** решения, что ценно в теоретических задачах (например, при анализе чувствительности решения к изменениям параметров).

---
### ==19. Системы линейных уравнений. Основные понятия.

Система линейных уравнений — это совокупность уравнений, каждое из которых является **линейной комбинацией неизвестных**, приравненной к заданному числу (свободному члену). Такие системы являются центральным объектом изучения в линейной алгебре и находят широкое применение в физике, экономике, инженерии и компьютерных науках.

#### Общая форма

Система из $m$ линейных уравнений с $n$ неизвестными над полем $\mathbb{F}$ (обычно $\mathbb{R}$ или $\mathbb{C}$) записывается как:
$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1, \\
a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_2, \\
\quad\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n = b_m,
\end{cases}
$$
где:
- $x_1, \dots, x_n$ — **неизвестные**,
- $a_{ij} \in \mathbb{F}$ — **коэффициенты**,
- $b_i \in \mathbb{F}$ — **свободные члены**.

#### Матричная запись

Систему можно компактно записать в виде:
$$
A\mathbf{x} = \mathbf{b},
$$
где:
- $A = (a_{ij})_{m\times n}$ — **основная матрица системы**,
- $\mathbf{x} = (x_1, \dots, x_n)^T$ — **вектор неизвестных**,
- $\mathbf{b} = (b_1, \dots, b_m)^T$ — **вектор свободных членов**.

**Расширенная матрица** системы — это матрица $\widetilde{A} = [A \mid \mathbf{b}]$, полученная присоединением столбца $\mathbf{b}$ к матрице $A$.

#### Классификация систем

1. **Совместная система** — имеет хотя бы одно решение.
2. **Несовместная система** — не имеет решений.
3. **Определённая система** — совместна и имеет **единственное** решение.
4. **Неопределённая система** — совместна и имеет **бесконечно много** решений.

#### Однородные и неоднородные системы

- **Однородная**: все $b_i = 0$, то есть $A\mathbf{x} = \mathbf{0}$.  
  Всегда совместна (имеет тривиальное решение $\mathbf{x} = \mathbf{0}$). Нетривиальные решения существуют тогда и только тогда, когда $\operatorname{rank} A < n$.

- **Неоднородная**: хотя бы один $b_i \ne 0$.

#### Эквивалентные системы

Две системы называются **эквивалентными**, если множества их решений совпадают. Эквивалентность сохраняется при:
- перестановке уравнений,
- умножении уравнения на ненулевое число,
- прибавлении к одному уравнению другого, умноженного на число.

Эти преобразования соответствуют **элементарным преобразованиям строк** расширенной матрицы.

#### Примеры

1. **Определённая система**:
   $$
   \begin{cases}
   x + y = 2, \\
   x - y = 0
   \end{cases}
   \Rightarrow (x,y) = (1,1).
   $$

2. **Неопределённая система**:
   $$
   \begin{cases}
   x + y = 1, \\
   2x + 2y = 2
   \end{cases}
   \Rightarrow x = 1 - t,\ y = t,\ t \in \mathbb{R}.
   $$

3. **Несовместная система**:
   $$
   \begin{cases}
   x + y = 1, \\
   x + y = 2
   \end{cases}
   \Rightarrow \text{противоречие, решений нет}.
   $$

#### Теоретическая основа

- **Теорема Кронекера–Капелли**: система совместна $\Leftrightarrow$ $\operatorname{rank} A = \operatorname{rank} \widetilde{A}$.
- **Теорема о ранге**: если система совместна и $\operatorname{rank} A = r$, то множество решений зависит от $n - r$ свободных параметров.

---
### ==20. Векторные пространства. Линейная зависимость векторов. Конечномерные векторные пространства.

#### Векторное (линейное) пространство

**Векторным пространством** над полем $\mathbb{F}$ называется непустое множество $V$, на котором определены две операции:
1. **Сложение векторов**: $V \times V \to V$, $(\mathbf{u}, \mathbf{v}) \mapsto \mathbf{u} + \mathbf{v}$,
2. **Умножение вектора на скаляр**: $\mathbb{F} \times V \to V$, $(\lambda, \mathbf{v}) \mapsto \lambda\mathbf{v}$,

удовлетворяющие следующим аксиомам:
- **Коммутативность и ассоциативность сложения**,
- **Существование нулевого вектора** $\mathbf{0} \in V$,
- **Существование противоположного вектора** $-\mathbf{v}$,
- **Ассоциативность умножения на скаляры**: $\lambda(\mu\mathbf{v}) = (\lambda\mu)\mathbf{v}$,
- **Дистрибутивность**:  
  $\lambda(\mathbf{u} + \mathbf{v}) = \lambda\mathbf{u} + \lambda\mathbf{v}$,  
  $(\lambda + \mu)\mathbf{v} = \lambda\mathbf{v} + \mu\mathbf{v}$,
- **Единичный скаляр**: $1\cdot\mathbf{v} = \mathbf{v}$.

Примеры: $\mathbb{R}^n$, пространство многочленов степени $\le n$, пространство непрерывных функций на отрезке.

#### Линейная зависимость и независимость

Пусть $\mathbf{v}_1, \dots, \mathbf{v}_k \in V$.

- Система векторов называется **линейно зависимой**, если существуют скаляры $\lambda_1, \dots, \lambda_k \in \mathbb{F}$, **не все нулевые**, такие что:
  $$
  \lambda_1\mathbf{v}_1 + \dots + \lambda_k\mathbf{v}_k = \mathbf{0}.
  $$
- В противном случае система называется **линейно независимой**.

**Свойства**:
- Любая подсистема линейно независимой системы линейно независима.
- Система, содержащая нулевой вектор, линейно зависима.
- В $\mathbb{F}^n$ любая система из более чем $n$ векторов линейно зависима.

#### Базис и размерность

- **Базисом** векторного пространства $V$ называется **максимальная линейно независимая** система векторов, через которую можно выразить любой вектор пространства (то есть она **порождает** всё пространство).
- Все базисы одного и того же пространства содержат **одно и то же число векторов**. Это число называется **размерностью** пространства и обозначается $\dim V$.

#### Конечномерные векторные пространства

Пространство $V$ называется **конечномерным**, если оно обладает конечным базисом. В этом случае:
- Любой вектор $\mathbf{v} \in V$ единственным образом представляется в виде:
  $$
  \mathbf{v} = x_1\mathbf{e}_1 + \dots + x_n\mathbf{e}_n,
  $$
  где $\{\mathbf{e}_1, \dots, \mathbf{e}_n\}$ — базис, а $(x_1, \dots, x_n)$ — **координаты** вектора $\mathbf{v}$ в этом базисе.
- Изоморфизм: любое $n$-мерное векторное пространство над $\mathbb{F}$ изоморфно $\mathbb{F}^n$.

#### Примеры

- $\mathbb{R}^3$ — трёхмерное пространство; стандартный базис: $\mathbf{e}_1 = (1,0,0),\ \mathbf{e}_2 = (0,1,0),\ \mathbf{e}_3 = (0,0,1)$.
- Пространство многочленов степени $\le 2$: базис $\{1, x, x^2\}$, размерность 3.

#### Теорема о замене (Штейница)

Если в пространстве $V$ существует линейно независимая система из $k$ векторов и порождающая система из $m$ векторов, то $k \le m$. В частности, размерность определена однозначно.

#### Значение

Понятия базиса и размерности позволяют:
- вводить координаты и сводить абстрактные задачи к вычислениям в $\mathbb{F}^n$,
- определять ранг матрицы как размерность пространства её строк или столбцов,
- строить теорию линейных операторов и их матричных представлений.

---
### ==21. Смешанное произведение векторов. Практическое применение.

**Смешанное произведение** (или **скалярно-векторное произведение**) трёх векторов $\mathbf{a}, \mathbf{b}, \mathbf{c} \in \mathbb{R}^3$ определяется как скалярное произведение одного из векторов на векторное произведение двух других:
$$
(\mathbf{a}, \mathbf{b}, \mathbf{c}) = \mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}).
$$

Эквивалентно, оно выражается определителем, составленным из координат векторов:
$$
(\mathbf{a}, \mathbf{b}, \mathbf{c}) =
\begin{vmatrix}
a_1 & a_2 & a_3 \\
b_1 & b_2 & b_3 \\
c_1 & c_2 & c_3
\end{vmatrix}.
$$

#### Основные свойства

1. **Антисимметричность**: при перестановке любых двух векторов знак произведения меняется:
   $$
   (\mathbf{a}, \mathbf{b}, \mathbf{c}) = -(\mathbf{b}, \mathbf{a}, \mathbf{c}) = -(\mathbf{a}, \mathbf{c}, \mathbf{b}) = \dots
   $$

2. **Циклическая симметрия**:
   $$
   (\mathbf{a}, \mathbf{b}, \mathbf{c}) = (\mathbf{b}, \mathbf{c}, \mathbf{a}) = (\mathbf{c}, \mathbf{a}, \mathbf{b}).
   $$

3. **Линейность по каждому аргументу**:
   $$
   (\lambda\mathbf{a} + \mu\mathbf{a}', \mathbf{b}, \mathbf{c}) = \lambda(\mathbf{a}, \mathbf{b}, \mathbf{c}) + \mu(\mathbf{a}', \mathbf{b}, \mathbf{c}).
   $$

4. **Критерий компланарности**:  
   $$
   (\mathbf{a}, \mathbf{b}, \mathbf{c}) = 0 \quad \Leftrightarrow \quad \text{векторы } \mathbf{a}, \mathbf{b}, \mathbf{c} \text{ компланарны (лежат в одной плоскости)}.
   $$

#### Геометрический смысл

Абсолютное значение смешанного произведения равно **объёму параллелепипеда**, построенного на векторах $\mathbf{a}, \mathbf{b}, \mathbf{c}$ как на рёбрах, исходящих из одной вершины:
$$
V = |(\mathbf{a}, \mathbf{b}, \mathbf{c})|.
$$

Знак произведения указывает на **ориентацию тройки векторов**:
- Положительный — если тройка **правая** (соответствует ориентации стандартного базиса),
- Отрицательный — если **левая**.

Объём **тетраэдра**, построенного на тех же векторах, равен:
$$
V_{\text{тетр}} = \frac{1}{6} |(\mathbf{a}, \mathbf{b}, \mathbf{c})|.
$$

#### Практическое применение

1. **Геометрия и компьютерная графика**:
   - Проверка компланарности точек или векторов,
   - Вычисление объёмов трёхмерных объектов,
   - Определение ориентации тройки точек (например, при построении нормалей в 3D-моделировании).

2. **Физика**:
   - В механике — вычисление **момента импульса** и **работы в трёхмерном пространстве**,
   - В электродинамике — при анализе потоков векторных полей через замкнутые поверхности (в сочетании с интегральными теоремами).

3. **Робототехника и навигация**:
   - Определение положения объекта в пространстве относительно базиса,
   - Проверка, лежит ли точка внутри тетраэдра (используется в методе конечных элементов).

4. **Математический анализ**:
   - **Якобиан** замены переменных в тройном интеграле — это смешанное произведение частных производных:
     $$
     J = \left( \frac{\partial \mathbf{r}}{\partial u}, \frac{\partial \mathbf{r}}{\partial v}, \frac{\partial \mathbf{r}}{\partial w} \right),
     $$
     где $\mathbf{r}(u,v,w)$ — вектор положения в криволинейных координатах.  
     Объём элементарного параллелепипеда: $dV = |J|\,du\,dv\,dw$.

#### Пример

Найти объём параллелепипеда, построенного на векторах  
$\mathbf{a} = (1,0,0),\ \mathbf{b} = (0,2,0),\ \mathbf{c} = (0,0,3)$.

$$
(\mathbf{a}, \mathbf{b}, \mathbf{c}) =
\begin{vmatrix}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 3
\end{vmatrix} = 1\cdot2\cdot3 = 6.
$$

Объём: $V = |6| = 6$ — что совпадает с объёмом прямоугольного параллелепипеда $1\times2\times3$.

---
### ==22. Векторное произведение векторов. Задачи на векторное произведение векторов.

**Векторное произведение** двух векторов $\mathbf{a}, \mathbf{b} \in \mathbb{R}^3$ — это вектор $\mathbf{c} = \mathbf{a} \times \mathbf{b}$, обладающий следующими свойствами:

1. $\mathbf{c} \perp \mathbf{a}$ и $\mathbf{c} \perp \mathbf{b}$,
2. Тройка $(\mathbf{a}, \mathbf{b}, \mathbf{c})$ — **правая**,
3. Длина $|\mathbf{c}| = \|\mathbf{a}\| \|\mathbf{b}\| \sin\varphi$, где $\varphi$ — угол между $\mathbf{a}$ и $\mathbf{b}$.

В координатах:
$$
\mathbf{a} \times \mathbf{b} =
\begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
a_1 & a_2 & a_3 \\
b_1 & b_2 & b_3
\end{vmatrix}
= (a_2b_3 - a_3b_2,\ a_3b_1 - a_1b_3,\ a_1b_2 - a_2b_1).
$$

#### Основные свойства

- **Антисимметричность**: $\mathbf{a} \times \mathbf{b} = -(\mathbf{b} \times \mathbf{a})$,
- **Линейность**: $\mathbf{a} \times (\lambda\mathbf{b} + \mu\mathbf{c}) = \lambda(\mathbf{a} \times \mathbf{b}) + \mu(\mathbf{a} \times \mathbf{c})$,
- $\mathbf{a} \times \mathbf{a} = \mathbf{0}$,
- $\mathbf{a} \times \mathbf{b} = \mathbf{0} \Leftrightarrow \mathbf{a} \parallel \mathbf{b}$ (векторы коллинеарны).

#### Геометрический смысл

Длина векторного произведения равна **площади параллелограмма**, построенного на $\mathbf{a}$ и $\mathbf{b}$:
$$
S = \|\mathbf{a} \times \mathbf{b}\|.
$$

Площадь **треугольника** с теми же сторонами:
$$
S_{\triangle} = \frac{1}{2} \|\mathbf{a} \times \mathbf{b}\|.
$$

#### Типовые задачи и их решения

##### 1. **Нахождение вектора, перпендикулярного двум заданным**

*Задача:* Найти вектор, перпендикулярный $\mathbf{a} = (1,2,3)$ и $\mathbf{b} = (0,1,1)$.

*Решение:*  
$$
\mathbf{a} \times \mathbf{b} =
\begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
1 & 2 & 3 \\
0 & 1 & 1
\end{vmatrix}
= (2\cdot1 - 3\cdot1,\ 3\cdot0 - 1\cdot1,\ 1\cdot1 - 2\cdot0)
= (-1, -1, 1).
$$

##### 2. **Вычисление площади параллелограмма или треугольника**

*Задача:* Найти площадь треугольника с вершинами $A(1,0,0),\ B(0,1,0),\ C(0,0,1)$.

*Решение:*  
Векторы сторон: $\overrightarrow{AB} = (-1,1,0),\ \overrightarrow{AC} = (-1,0,1)$.  
$$
\overrightarrow{AB} \times \overrightarrow{AC} =
\begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
-1 & 1 & 0 \\
-1 & 0 & 1
\end{vmatrix}
= (1, 1, 1).
$$
Длина: $\|\mathbf{c}\| = \sqrt{1^2 + 1^2 + 1^2} = \sqrt{3}$.  
Площадь треугольника: $S = \frac{1}{2}\sqrt{3}$.

##### 3. **Проверка коллинеарности векторов**

*Задача:* Коллинеарны ли $\mathbf{a} = (2,4,6)$ и $\mathbf{b} = (1,2,3)$?

*Решение:*  
$\mathbf{a} = 2\mathbf{b}$ ⇒ коллинеарны. Либо:  
$\mathbf{a} \times \mathbf{b} = \mathbf{0}$ — проверка через векторное произведение.

##### 4. **Нахождение момента силы**

*Задача (физика):* Сила $\mathbf{F} = (0,0,10)$ приложена в точке с радиус-вектором $\mathbf{r} = (1,2,0)$. Найти момент силы относительно начала координат.

*Решение:*  
$$
\mathbf{M} = \mathbf{r} \times \mathbf{F} = 
\begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
1 & 2 & 0 \\
0 & 0 & 10
\end{vmatrix}
= (20, -10, 0).
$$

#### Применение

- **Механика**: момент силы $\mathbf{M} = \mathbf{r} \times \mathbf{F}$,
- **Электромагнетизм**: сила Лоренца $\mathbf{F} = q(\mathbf{v} \times \mathbf{B})$,
- **Компьютерная графика**: вычисление нормалей к поверхностям,
- **Робототехника**: определение угловых скоростей и вращений.

---
### ==23. Основные алгебраические структуры. Понятия кольца, поля. Основные определения.

Алгебраические структуры — это множества, на которых заданы одна или несколько операций, удовлетворяющих определённым аксиомам. Наиболее важные из них — **группы**, **кольца** и **поля**. В данном вопросе рассматриваются последние два.

#### Кольцо

**Кольцом** называется непустое множество $R$, на котором определены две бинарные операции:
- **сложение** ($+$),
- **умножение** ($\cdot$),

удовлетворяющие следующим аксиомам:

1. **$(R, +)$ — абелева (коммутативная) группа**:
   - сложение ассоциативно: $(a + b) + c = a + (b + c)$,
   - существует нулевой элемент $0 \in R$: $a + 0 = a$,
   - для каждого $a \in R$ существует противоположный элемент $-a$: $a + (-a) = 0$,
   - сложение коммутативно: $a + b = b + a$.

2. **Умножение ассоциативно**:  
   $(a \cdot b) \cdot c = a \cdot (b \cdot c)$ для всех $a,b,c \in R$.

3. **Дистрибутивность умножения относительно сложения**:  
   $a(b + c) = ab + ac$,  
   $(a + b)c = ac + bc$.

Если дополнительно выполняется:
- **Коммутативность умножения**: $ab = ba$ — кольцо называется **коммутативным**.
- **Существование единичного элемента** $1 \in R$, $1 \ne 0$, такого что $1 \cdot a = a \cdot 1 = a$ — кольцо называется **кольцом с единицей**.

**Примеры колец**:
- $\mathbb{Z}$ — кольцо целых чисел (коммутативное, с единицей),
- $\mathbb{Z}_n$ — кольцо вычетов по модулю $n$,
- $M_n(\mathbb{R})$ — кольцо квадратных матриц порядка $n$ (не коммутативное при $n \ge 2$),
- Множество чётных целых чисел — кольцо без единицы.

#### Поле

**Полем** называется **коммутативное кольцо с единицей**, в котором **каждый ненулевой элемент обратим**, то есть для любого $a \in F$, $a \ne 0$, существует $a^{-1} \in F$, такой что $a \cdot a^{-1} = 1$.

Таким образом, поле — это множество $F$, где определены сложение и умножение, и выполняются все следующие свойства:

1. $(F, +)$ — абелева группа с нулём $0$,
2. $(F \setminus \{0\}, \cdot)$ — абелева группа с единицей $1$,
3. Умножение дистрибутивно относительно сложения.

**Примеры полей**:
- $\mathbb{Q}$ — поле рациональных чисел,
- $\mathbb{R}$ — поле вещественных чисел,
- $\mathbb{C}$ — поле комплексных чисел,
- $\mathbb{Z}_p$ — поле вычетов по простому модулю $p$ (например, $\mathbb{Z}_2 = \{0,1\}$).

**Важное замечание**: $\mathbb{Z}_n$ является полем **тогда и только тогда**, когда $n$ — **простое число**.

#### Сравнение

| Свойство | Кольцо | Поле |
|--------|--------|------|
| Сложение | Абелева группа | Абелева группа |
| Умножение | Ассоциативно, дистрибутивно | Ассоциативно, коммутативно, дистрибутивно |
| Единица | Может отсутствовать | Обязательно есть |
| Обратные элементы (для умножения) | Не требуются | Существуют для всех $a \ne 0$ |

---
### ==24. Скалярное произведение векторов. Действия сложения векторов, умножения вектора на число.

Этот вопрос объединяет две темы: **скалярное произведение** и **основные линейные операции над векторами**.

#### 1. Сложение векторов и умножение вектора на число

Пусть $\mathbf{a} = (a_1, a_2, \dots, a_n)$, $\mathbf{b} = (b_1, b_2, \dots, b_n)$ — векторы в $\mathbb{R}^n$, $\lambda \in \mathbb{R}$ — скаляр.

- **Сложение векторов**:
  $$
  \mathbf{a} + \mathbf{b} = (a_1 + b_1,\ a_2 + b_2,\ \dots,\ a_n + b_n).
  $$

- **Умножение вектора на число**:
  $$
  \lambda \mathbf{a} = (\lambda a_1,\ \lambda a_2,\ \dots,\ \lambda a_n).
  $$

Эти операции удовлетворяют аксиомам векторного пространства:
- ассоциативность и коммутативность сложения,
- существование нулевого вектора $\mathbf{0} = (0,\dots,0)$,
- существование противоположного вектора $-\mathbf{a}$,
- дистрибутивность и совместимость с умножением скаляров.

Геометрически:
- Сложение — по **правилу параллелограмма** или **треугольника**,
- Умножение на $\lambda > 0$ — растяжение/сжатие в $\lambda$ раз в том же направлении,
- Умножение на $\lambda < 0$ — растяжение и **изменение направления** на противоположное.

#### 2. Скалярное произведение

**Скалярным произведением** векторов $\mathbf{a}, \mathbf{b} \in \mathbb{R}^n$ называется число:
$$
\mathbf{a} \cdot \mathbf{b} = a_1 b_1 + a_2 b_2 + \dots + a_n b_n = \sum_{i=1}^{n} a_i b_i.
$$

В $\mathbb{R}^2$ и $\mathbb{R}^3$ оно также выражается через длины векторов и угол $\varphi$ между ними:
$$
\mathbf{a} \cdot \mathbf{b} = \|\mathbf{a}\| \|\mathbf{b}\| \cos\varphi,
$$
где $\|\mathbf{a}\| = \sqrt{a_1^2 + \dots + a_n^2}$ — **длина (норма)** вектора.

#### Свойства скалярного произведения

1. **Коммутативность**: $\mathbf{a} \cdot \mathbf{b} = \mathbf{b} \cdot \mathbf{a}$,
2. **Линейность по первому аргументу**:  
   $(\lambda\mathbf{a} + \mu\mathbf{b}) \cdot \mathbf{c} = \lambda(\mathbf{a} \cdot \mathbf{c}) + \mu(\mathbf{b} \cdot \mathbf{c})$,
3. **Положительная определённость**:  
   $\mathbf{a} \cdot \mathbf{a} \ge 0$, и $\mathbf{a} \cdot \mathbf{a} = 0 \Leftrightarrow \mathbf{a} = \mathbf{0}$.

#### Геометрический смысл

- Скалярное произведение равно **произведению длины одного вектора на проекцию другого на его направление**:
  $$
  \mathbf{a} \cdot \mathbf{b} = \|\mathbf{a}\| \cdot \operatorname{proj}_{\mathbf{a}} \mathbf{b}.
  $$
- Если $\mathbf{a} \cdot \mathbf{b} = 0$, векторы **ортогональны** (перпендикулярны).
- Угол между векторами:
  $$
  \cos\varphi = \frac{\mathbf{a} \cdot \mathbf{b}}{\|\mathbf{a}\| \|\mathbf{b}\|}.
  $$

#### Примеры применения

- **Физика**: работа силы $A = \mathbf{F} \cdot \mathbf{s}$,
- **Компьютерная графика**: определение освещённости поверхности (через угол между нормалью и источником света),
- **Машинное обучение**: вычисление косинусного сходства между векторами признаков.

#### Связь с линейными операциями

Скалярное произведение **согласовано** с линейными операциями:
- $\|\lambda\mathbf{a}\| = |\lambda| \cdot \|\mathbf{a}\|$,
- $\|\mathbf{a} + \mathbf{b}\|^2 = \|\mathbf{a}\|^2 + 2\mathbf{a} \cdot \mathbf{b} + \|\mathbf{b}\|^2$ (теорема косинусов в векторной форме).

---
### ==25. Линейные преобразования векторных пространств. Собственные векторы и собственные значения линейного преобразования.

#### Линейные преобразования

Пусть $V$ — векторное пространство над полем $\mathbb{F}$ (обычно $\mathbb{R}$ или $\mathbb{C}$).  
**Линейным преобразованием** (или **линейным оператором**) пространства $V$ называется отображение $T: V \to V$, удовлетворяющее условиям:

1. **Аддитивность**: $T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})$ для всех $\mathbf{u}, \mathbf{v} \in V$,
2. **Однородность**: $T(\lambda \mathbf{v}) = \lambda T(\mathbf{v})$ для всех $\lambda \in \mathbb{F}$, $\mathbf{v} \in V$.

Если $V$ конечномерно и зафиксирован базис $\{\mathbf{e}_1, \dots, \mathbf{e}_n\}$, то любому линейному преобразованию $T$ однозначно соответствует **матрица** $A = (a_{ij})$, такая что:
$$
T(\mathbf{e}_j) = \sum_{i=1}^{n} a_{ij} \mathbf{e}_i.
$$
Тогда действие $T$ на произвольный вектор $\mathbf{x}$ с координатами $\mathbf{x} = (x_1, \dots, x_n)^T$ записывается как:
$$
T(\mathbf{x}) = A\mathbf{x}.
$$

#### Собственные векторы и собственные значения

Ненулевой вектор $\mathbf{v} \in V$ называется **собственным вектором** линейного преобразования $T$, если существует скаляр $\lambda \in \mathbb{F}$, такой что:
$$
T(\mathbf{v}) = \lambda \mathbf{v}.
$$
Скаляр $\lambda$ называется **собственным значением** (или **характеристическим числом**), соответствующим собственному вектору $\mathbf{v}$.

Геометрически это означает, что при действии $T$ вектор $\mathbf{v}$ **не меняет направления**, а лишь растягивается (или сжимается, или меняет знак) в $\lambda$ раз.

#### Нахождение собственных значений и векторов

Пусть $A$ — матрица преобразования $T$ в некотором базисе. Уравнение $T(\mathbf{v}) = \lambda \mathbf{v}$ эквивалентно:
$$
A\mathbf{v} = \lambda \mathbf{v} \quad \Leftrightarrow \quad (A - \lambda E)\mathbf{v} = \mathbf{0},
$$
где $E$ — единичная матрица.

Эта однородная система имеет **нетривиальное решение** тогда и только тогда, когда:
$$
\det(A - \lambda E) = 0.
$$
Это уравнение называется **характеристическим уравнением**, а многочлен $\chi_A(\lambda) = \det(A - \lambda E)$ — **характеристическим многочленом**.

Корни $\lambda_1, \dots, \lambda_k$ характеристического уравнения — **собственные значения**. Для каждого $\lambda_i$ решается система $(A - \lambda_i E)\mathbf{v} = \mathbf{0}$, и её ненулевые решения — **собственные векторы**, соответствующие $\lambda_i$.

#### Свойства

- Собственные векторы, соответствующие **различным** собственным значениям, **линейно независимы**.
- Если матрица $A$ имеет $n$ линейно независимых собственных векторов, то она **диагонализируема**: существует невырожденная матрица $P$, такая что $P^{-1}AP = D$, где $D$ — диагональная матрица из собственных значений.
- Для вещественной симметричной матрицы все собственные значения — **вещественные**, а собственные векторы можно выбрать **ортогональными**.

#### Пример

Пусть $A = \begin{pmatrix}4 & 1\\ 2 & 3\end{pmatrix}$.

Характеристическое уравнение:
$$
\det\begin{pmatrix}4-\lambda & 1\\ 2 & 3-\lambda\end{pmatrix} = (4-\lambda)(3-\lambda) - 2 = \lambda^2 - 7\lambda + 10 = 0.
$$
Корни: $\lambda_1 = 2$, $\lambda_2 = 5$.

Для $\lambda_1 = 2$:  
$(A - 2E)\mathbf{v} = \begin{pmatrix}2 & 1\\ 2 & 1\end{pmatrix}\mathbf{v} = \mathbf{0}$ ⇒ $\mathbf{v}_1 = (1, -2)^T$.

Для $\lambda_2 = 5$:  
$(A - 5E)\mathbf{v} = \begin{pmatrix}-1 & 1\\ 2 & -2\end{pmatrix}\mathbf{v} = \mathbf{0}$ ⇒ $\mathbf{v}_2 = (1, 1)^T$.

#### Применение

- **Механика**: главные оси инерции, нормальные колебания,
- **Квантовая физика**: наблюдаемые величины представлены эрмитовыми операторами, их собственные значения — возможные результаты измерений,
- **Машинное обучение**: метод главных компонент (PCA) основан на собственных векторах ковариационной матрицы,
- **Дифференциальные уравнения**: решение систем линейных ОДУ с постоянными коэффициентами.

---
### ==26. Линейное (векторное) пространство. Конечномерные линейные пространства, базис и размерность.

#### Линейное (векторное) пространство

**Линейным пространством** над полем $\mathbb{F}$ называется множество $V$, на котором определены операции сложения векторов и умножения на скаляры, удовлетворяющие стандартным аксиомам (ассоциативность, коммутативность, существование нуля и противоположного элемента, дистрибутивность и т.д.).

Примеры:
- $\mathbb{R}^n$ — пространство строк длины $n$,
- $\mathcal{P}_n$ — пространство многочленов степени $\le n$,
- $C[a,b]$ — пространство непрерывных функций на отрезке.

#### Линейная зависимость

Система векторов $\mathbf{v}_1, \dots, \mathbf{v}_k \in V$ называется **линейно зависимой**, если существуют скаляры $\lambda_1, \dots, \lambda_k \in \mathbb{F}$, не все нулевые, такие что:
$$
\lambda_1\mathbf{v}_1 + \dots + \lambda_k\mathbf{v}_k = \mathbf{0}.
$$
В противном случае система — **линейно независима**.

#### Базис

**Базисом** пространства $V$ называется **упорядоченная линейно независимая система векторов**, через которую можно выразить любой вектор пространства.

Формально, система $\{\mathbf{e}_1, \dots, \mathbf{e}_n\} \subset V$ — базис, если:
1. $\mathbf{e}_1, \dots, \mathbf{e}_n$ — линейно независимы,
2. Для любого $\mathbf{v} \in V$ существуют **единственные** скаляры $x_1, \dots, x_n$, такие что:
   $$
   \mathbf{v} = x_1\mathbf{e}_1 + \dots + x_n\mathbf{e}_n.
   $$

Числа $x_1, \dots, x_n$ называются **координатами** вектора $\mathbf{v}$ в данном базисе.

#### Размерность

Если в пространстве $V$ существует конечный базис из $n$ векторов, то $V$ называется **конечномерным**, а число $n$ — **размерностью** пространства, обозначается $\dim V = n$.

**Теорема**: все базисы одного и того же конечномерного пространства содержат одинаковое число векторов.

Если такого конечного базиса нет, пространство называется **бесконечномерным** (например, пространство всех многочленов).

#### Примеры

- $\mathbb{R}^3$: стандартный базис $\{(1,0,0), (0,1,0), (0,0,1)\}$, $\dim = 3$.
- $\mathcal{P}_2$ (многочлены степени $\le 2$): базис $\{1, x, x^2\}$, $\dim = 3$.
- Пространство решений однородной системы $A\mathbf{x} = \mathbf{0}$ с $\operatorname{rank} A = r$: $\dim = n - r$.

#### Изоморфизм

Любое $n$-мерное векторное пространство над $\mathbb{F}$ **изоморфно** $\mathbb{F}^n$. Это позволяет сводить абстрактные задачи к вычислениям с координатными столбцами.

#### Значение

Понятия базиса и размерности позволяют:
- вводить координаты и использовать матричный аппарат,
- определять ранг матрицы как размерность пространства её строк,
- строить теорию линейных операторов и их инвариантов.

---
### ==27. Теорема Кронекера–Капелли.

**Теорема Кронекера–Капелли** — фундаментальный результат в теории систем линейных уравнений, устанавливающий необходимое и достаточное условие их совместности.

#### Формулировка

Система линейных уравнений  
$$
A\mathbf{x} = \mathbf{b}
$$  
совместна **тогда и только тогда**, когда **ранг основной матрицы системы равен рангу её расширенной матрицы**, то есть  
$$
\operatorname{rank} A = \operatorname{rank} \widetilde{A},
$$  
где $\widetilde{A} = [A \mid \mathbf{b}]$ — матрица, полученная присоединением столбца свободных членов $\mathbf{b}$ к основной матрице $A$.

#### Доказательство (основная идея)

- **Необходимость**:  
  Пусть система совместна, то есть существует вектор $\mathbf{x}_0$, такой что $A\mathbf{x}_0 = \mathbf{b}$. Это означает, что столбец $\mathbf{b}$ является линейной комбинацией столбцов матрицы $A$:  
  $$
  \mathbf{b} = x_1^{(0)}\mathbf{a}_1 + x_2^{(0)}\mathbf{a}_2 + \dots + x_n^{(0)}\mathbf{a}_n,
  $$  
  где $\mathbf{a}_j$ — $j$-й столбец $A$. Следовательно, добавление $\mathbf{b}$ к системе столбцов $A$ не увеличивает их линейную оболочку, а значит, не увеличивает ранг: $\operatorname{rank} \widetilde{A} = \operatorname{rank} A$.

- **Достаточность**:  
  Пусть $\operatorname{rank} A = \operatorname{rank} \widetilde{A} = r$. Тогда максимальная линейно независимая подсистема столбцов $A$ остаётся таковой и в $\widetilde{A}$. Следовательно, столбец $\mathbf{b}$ выражается как линейная комбинация столбцов $A$, то есть существует $\mathbf{x}_0$, для которого $A\mathbf{x}_0 = \mathbf{b}$ — система совместна.

#### Следствия

1. Если $\operatorname{rank} A \ne \operatorname{rank} \widetilde{A}$, система **несовместна**.
2. Если система совместна и $\operatorname{rank} A = n$ (число неизвестных), то решение **единственно**.
3. Если система совместна и $\operatorname{rank} A = r < n$, то множество решений зависит от $n - r$ **свободных параметров** (неопределённая система).

#### Пример

Рассмотрим систему:
$$
\begin{cases}
x + y + z = 2, \\
2x + 2y + 2z = 4, \\
3x + 3y + 3z = 6.
\end{cases}
$$

Основная матрица:
$$
A = \begin{pmatrix}
1 & 1 & 1\\
2 & 2 & 2\\
3 & 3 & 3
\end{pmatrix}, \quad
\widetilde{A} = \begin{pmatrix}
1 & 1 & 1 & \vert & 2\\
2 & 2 & 2 & \vert & 4\\
3 & 3 & 3 & \vert & 6
\end{pmatrix}.
$$

$\operatorname{rank} A = 1$, $\operatorname{rank} \widetilde{A} = 1$ ⇒ система совместна.  
Число неизвестных $n = 3$, ранг $r = 1$ ⇒ $3 - 1 = 2$ свободных переменных ⇒ бесконечно много решений.

#### Историческая справка

Теорема названа в честь немецкого математика **Леопольда Кронекера** и итальянского математика **Альфредо Капелли**, которые независимо внесли вклад в развитие теории линейных систем в XIX веке.

#### Значение

Теорема Кронекера–Капелли:
- лежит в основе **метода Гаусса**,
- позволяет **классифицировать** любую систему линейных уравнений,
- служит мостом между **алгебраической** и **геометрической** интерпретацией линейных систем (через линейные оболочки и подпространства).

---
### ==28. Векторные пространства. Линейная зависимость векторов.

#### Векторное пространство

**Векторным (линейным) пространством** над полем $\mathbb{F}$ называется множество $V$, на котором определены две операции:
- **сложение векторов**: $V \times V \to V$,
- **умножение вектора на скаляр**: $\mathbb{F} \times V \to V$,

удовлетворяющие стандартным аксиомам (ассоциативность, коммутативность сложения, существование нуля, противоположного элемента, дистрибутивность и т.д.).

Примеры: $\mathbb{R}^n$, пространство многочленов, пространство решений однородной системы.

#### Линейная комбинация

Пусть $\mathbf{v}_1, \dots, \mathbf{v}_k \in V$, $\lambda_1, \dots, \lambda_k \in \mathbb{F}$. Выражение  
$$
\lambda_1\mathbf{v}_1 + \lambda_2\mathbf{v}_2 + \dots + \lambda_k\mathbf{v}_k
$$  
называется **линейной комбинацией** векторов $\mathbf{v}_1, \dots, \mathbf{v}_k$.

Множество всех линейных комбинаций данной системы векторов называется её **линейной оболочкой** и обозначается $\operatorname{span}\{\mathbf{v}_1, \dots, \mathbf{v}_k\}$.

#### Линейная зависимость

Система векторов $\mathbf{v}_1, \dots, \mathbf{v}_k$ называется **линейно зависимой**, если существует **нетривиальная** линейная комбинация, равная нулевому вектору, то есть существуют скаляры $\lambda_1, \dots, \lambda_k$, **не все равные нулю**, такие что:
$$
\lambda_1\mathbf{v}_1 + \dots + \lambda_k\mathbf{v}_k = \mathbf{0}.
$$

Если же равенство возможно **только при** $\lambda_1 = \dots = \lambda_k = 0$, система называется **линейно независимой**.

#### Эквивалентные условия линейной зависимости

Система $\{\mathbf{v}_1, \dots, \mathbf{v}_k\}$ линейно зависима **тогда и только тогда**, когда:
- хотя бы один из векторов выражается как линейная комбинация остальных,
- или ранг матрицы, составленной из этих векторов (как строк или столбцов), **меньше** числа векторов.

#### Основные свойства

1. Любая система, содержащая **нулевой вектор**, линейно зависима.
2. Система из **одного вектора** линейно зависима ⇔ этот вектор — нулевой.
3. Если система линейно независима, то любая её **подсистема** также линейно независима.
4. В пространстве размерности $n$ любая система из **более чем $n$** векторов линейно зависима.
5. Максимальное число линейно независимых векторов в пространстве равно его **размерности**.

#### Пример

Векторы $\mathbf{a} = (1,2,3)$, $\mathbf{b} = (2,4,6)$, $\mathbf{c} = (0,1,1)$ в $\mathbb{R}^3$:
- $\mathbf{b} = 2\mathbf{a}$ ⇒ $\mathbf{a}, \mathbf{b}$ — линейно зависимы,
- Система $\{\mathbf{a}, \mathbf{b}, \mathbf{c}\}$ — линейно зависима, так как содержит зависимую подсистему.

#### Геометрическая интерпретация

- Два вектора в $\mathbb{R}^3$ линейно зависимы ⇔ они **коллинеарны** (лежат на одной прямой).
- Три вектора в $\mathbb{R}^3$ линейно зависимы ⇔ они **компланарны** (лежат в одной плоскости).

#### Значение

Понятие линейной зависимости:
- лежит в основе определения **базиса** и **размерности**,
- используется при анализе **ранга матрицы**,
- необходимо для построения **фундаментальной системы решений** однородных систем,
- играет ключевую роль в теории **линейных операторов** и **спектрального анализа**.

---
### ==29. Геометрический смысл векторного произведения векторов.

**Векторное произведение** двух векторов $\mathbf{a}, \mathbf{b} \in \mathbb{R}^3$ — это вектор $\mathbf{c} = \mathbf{a} \times \mathbf{b}$, обладающий следующими геометрическими свойствами:

#### 1. Направление

Вектор $\mathbf{c}$ **перпендикулярен** обоим исходным векторам:
$$
\mathbf{c} \perp \mathbf{a}, \quad \mathbf{c} \perp \mathbf{b}.
$$
Таким образом, $\mathbf{c}$ ортогонален плоскости, содержащей $\mathbf{a}$ и $\mathbf{b}$ (если они не коллинеарны).

Направление $\mathbf{c}$ определяется **правилом правой руки**: если указательный палец направлен по $\mathbf{a}$, средний — по $\mathbf{b}$, то большой палец укажет направление $\mathbf{a} \times \mathbf{b}$.

Это означает, что тройка векторов $(\mathbf{a}, \mathbf{b}, \mathbf{a} \times \mathbf{b})$ образует **правую систему**.

#### 2. Длина

Длина векторного произведения равна:
$$
\|\mathbf{a} \times \mathbf{b}\| = \|\mathbf{a}\| \|\mathbf{b}\| \sin\varphi,
$$
где $\varphi$ — угол между векторами $\mathbf{a}$ и $\mathbf{b}$, $0 \le \varphi \le \pi$.

Геометрически это выражение представляет собой **площадь параллелограмма**, построенного на векторах $\mathbf{a}$ и $\mathbf{b}$ как на смежных сторонах:
$$
S_{\text{параллелограмма}} = \|\mathbf{a} \times \mathbf{b}\|.
$$

Следовательно, площадь **треугольника**, построенного на тех же векторах, равна:
$$
S_{\triangle} = \frac{1}{2} \|\mathbf{a} \times \mathbf{b}\|.
$$

#### 3. Вырожденный случай

Если $\mathbf{a}$ и $\mathbf{b}$ **коллинеарны** (то есть $\varphi = 0$ или $\varphi = \pi$), то $\sin\varphi = 0$, и
$$
\mathbf{a} \times \mathbf{b} = \mathbf{0}.
$$
Обратно, если $\mathbf{a} \times \mathbf{b} = \mathbf{0}$ и $\mathbf{a}, \mathbf{b} \ne \mathbf{0}$, то векторы коллинеарны.

#### Пример

Пусть $\mathbf{a} = (1,0,0)$, $\mathbf{b} = (0,1,0)$. Тогда:
$$
\mathbf{a} \times \mathbf{b} =
\begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
1 & 0 & 0 \\
0 & 1 & 0
\end{vmatrix}
= (0,0,1).
$$

- Направление: вдоль оси $Oz$ — перпендикулярно плоскости $Oxy$,
- Длина: $\|\mathbf{a}\| = 1$, $\|\mathbf{b}\| = 1$, $\varphi = 90^\circ$, $\sin\varphi = 1$ ⇒ $\|\mathbf{c}\| = 1$,
- Площадь параллелограмма (единичного квадрата): $1$ — верно.

#### Применение геометрического смысла

- **Компьютерная графика**: нормаль к поверхности треугольника вычисляется как векторное произведение двух его сторон.
- **Физика**: момент импульса $\mathbf{L} = \mathbf{r} \times \mathbf{p}$, сила Лоренца $\mathbf{F} = q(\mathbf{v} \times \mathbf{B})$ — величины, зависящие от «перпендикулярной компоненты».
- **Робототехника**: определение ориентации звеньев манипулятора в пространстве.

---
### ==30. Проекция вектора на ось. Разложение вектора по ортам координатных осей.

#### Проекция вектора на ось

Пусть задана ось $l$ с направляющим единичным вектором $\mathbf{e}_l$ (орт оси).  
**Проекцией** вектора $\mathbf{a}$ на ось $l$ называется скалярная величина:
$$
\operatorname{proj}_l \mathbf{a} = \|\mathbf{a}\| \cos\varphi,
$$
где $\varphi$ — угол между вектором $\mathbf{a}$ и положительным направлением оси $l$.

Эквивалентно, проекция выражается через скалярное произведение:
$$
\operatorname{proj}_l \mathbf{a} = \mathbf{a} \cdot \mathbf{e}_l.
$$

**Свойства проекции**:
- Проекция — **скаляр**, может быть положительной, отрицательной или нулевой.
- Если $\mathbf{a} \perp l$, то $\operatorname{proj}_l \mathbf{a} = 0$.
- Проекция линейна: $\operatorname{proj}_l (\lambda\mathbf{a} + \mu\mathbf{b}) = \lambda\,\operatorname{proj}_l \mathbf{a} + \mu\,\operatorname{proj}_l \mathbf{b}$.

#### Разложение вектора по ортам координатных осей

В декартовой прямоугольной системе координат в $\mathbb{R}^3$ вводятся **орты координатных осей**:
- $\mathbf{i} = (1,0,0)$ — орт оси $Ox$,
- $\mathbf{j} = (0,1,0)$ — орт оси $Oy$,
- $\mathbf{k} = (0,0,1)$ — орт оси $Oz$.

Любой вектор $\mathbf{a} \in \mathbb{R}^3$ можно единственным образом представить в виде линейной комбинации этих ортов:
$$
\mathbf{a} = a_x \mathbf{i} + a_y \mathbf{j} + a_z \mathbf{k},
$$
где:
- $a_x = \operatorname{proj}_{Ox} \mathbf{a} = \mathbf{a} \cdot \mathbf{i}$,
- $a_y = \operatorname{proj}_{Oy} \mathbf{a} = \mathbf{a} \cdot \mathbf{j}$,
- $a_z = \operatorname{proj}_{Oz} \mathbf{a} = \mathbf{a} \cdot \mathbf{k}$.

Числа $a_x, a_y, a_z$ называются **координатами** (или **компонентами**) вектора $\mathbf{a}$.

Аналогично в $\mathbb{R}^2$: $\mathbf{a} = a_x \mathbf{i} + a_y \mathbf{j}$.

#### Связь с длиной и направляющими косинусами

Длина вектора:
$$
\|\mathbf{a}\| = \sqrt{a_x^2 + a_y^2 + a_z^2}.
$$

**Направляющие косинусы** — косинусы углов $\alpha, \beta, \gamma$, которые вектор $\mathbf{a}$ образует с осями $Ox, Oy, Oz$ соответственно:
$$
\cos\alpha = \frac{a_x}{\|\mathbf{a}\|}, \quad
\cos\beta = \frac{a_y}{\|\mathbf{a}\|}, \quad
\cos\gamma = \frac{a_z}{\|\mathbf{a}\|}.
$$

Они удовлетворяют тождеству:
$$
\cos^2\alpha + \cos^2\beta + \cos^2\gamma = 1.
$$

#### Пример

Пусть $\mathbf{a} = (3, -4, 0)$. Тогда:
- $\operatorname{proj}_{Ox} \mathbf{a} = 3$, $\operatorname{proj}_{Oy} \mathbf{a} = -4$, $\operatorname{proj}_{Oz} \mathbf{a} = 0$,
- $\|\mathbf{a}\| = \sqrt{3^2 + (-4)^2} = 5$,
- $\cos\alpha = 3/5$, $\cos\beta = -4/5$, $\cos\gamma = 0$.

Разложение: $\mathbf{a} = 3\mathbf{i} - 4\mathbf{j} + 0\mathbf{k}$.

#### Значение

- Разложение по ортам позволяет **переходить от геометрических объектов к координатам**, что необходимо для вычислений.
- Проекции используются в физике (например, разложение силы на компоненты), аналитической геометрии, машинном обучении (при работе с признаками).

---
### ==31. Модуль вектора. Направляющие косинусы.

#### Модуль (длина) вектора

Пусть $\mathbf{a} = (a_1, a_2, \dots, a_n)$ — вектор в евклидовом пространстве $\mathbb{R}^n$.  
**Модулем** (или **длиной**, **нормой**) вектора $\mathbf{a}$ называется неотрицательное число:
$$
\|\mathbf{a}\| = \sqrt{a_1^2 + a_2^2 + \dots + a_n^2} = \sqrt{\sum_{i=1}^{n} a_i^2}.
$$

В трёхмерном пространстве $\mathbb{R}^3$ для вектора $\mathbf{a} = (a_x, a_y, a_z)$:
$$
\|\mathbf{a}\| = \sqrt{a_x^2 + a_y^2 + a_z^2}.
$$

Модуль обладает следующими свойствами:
1. $\|\mathbf{a}\| \ge 0$, и $\|\mathbf{a}\| = 0 \Leftrightarrow \mathbf{a} = \mathbf{0}$,
2. $\|\lambda \mathbf{a}\| = |\lambda| \cdot \|\mathbf{a}\|$ для любого скаляра $\lambda \in \mathbb{R}$,
3. Неравенство треугольника: $\|\mathbf{a} + \mathbf{b}\| \le \|\mathbf{a}\| + \|\mathbf{b}\|$.

Геометрически модуль — это **расстояние от начала координат до точки**, задаваемой концом вектора.

#### Направляющие косинусы

В трёхмерном пространстве $\mathbb{R}^3$ вектор $\mathbf{a} = (a_x, a_y, a_z)$ образует с координатными осями $Ox$, $Oy$, $Oz$ углы $\alpha$, $\beta$, $\gamma$ соответственно.  
**Направляющими косинусами** вектора $\mathbf{a}$ называются косинусы этих углов:
$$
\cos\alpha = \frac{a_x}{\|\mathbf{a}\|}, \quad
\cos\beta = \frac{a_y}{\|\mathbf{a}\|}, \quad
\cos\gamma = \frac{a_z}{\|\mathbf{a}\|}.
$$

Эти величины характеризуют **направление** вектора независимо от его длины.

#### Основное тождество направляющих косинусов

Для любого ненулевого вектора $\mathbf{a} \in \mathbb{R}^3$ выполняется соотношение:
$$
\cos^2\alpha + \cos^2\beta + \cos^2\gamma = 1.
$$

**Доказательство**:
$$
\cos^2\alpha + \cos^2\beta + \cos^2\gamma = 
\frac{a_x^2}{\|\mathbf{a}\|^2} + \frac{a_y^2}{\|\mathbf{a}\|^2} + \frac{a_z^2}{\|\mathbf{a}\|^2} = 
\frac{a_x^2 + a_y^2 + a_z^2}{\|\mathbf{a}\|^2} = 
\frac{\|\mathbf{a}\|^2}{\|\mathbf{a}\|^2} = 1.
$$

Это тождество отражает тот факт, что **единичный вектор**, имеющий те же направляющие косинусы, лежит на единичной сфере.

#### Единичный вектор (орт)

Единичный вектор, сонаправленный с $\mathbf{a}$, обозначается $\mathbf{a}_0$ и вычисляется как:
$$
\mathbf{a}_0 = \frac{\mathbf{a}}{\|\mathbf{a}\|} = (\cos\alpha,\ \cos\beta,\ \cos\gamma).
$$

Таким образом, направляющие косинусы — это **координаты единичного вектора**, указывающего в том же направлении, что и $\mathbf{a}$.

#### Пример

Пусть $\mathbf{a} = (1, 2, 2)$. Тогда:
- $\|\mathbf{a}\| = \sqrt{1^2 + 2^2 + 2^2} = \sqrt{9} = 3$,
- $\cos\alpha = \dfrac{1}{3},\quad \cos\beta = \dfrac{2}{3},\quad \cos\gamma = \dfrac{2}{3}$,
- Проверка: $\left(\dfrac{1}{3}\right)^2 + \left(\dfrac{2}{3}\right)^2 + \left(\dfrac{2}{3}\right)^2 = \dfrac{1+4+4}{9} = 1$ — верно.

#### Применение

- **Аналитическая геометрия**: задание направления прямой или нормали к плоскости.
- **Физика**: разложение векторов сил, скоростей, полей по направлениям.
- **Компьютерная графика**: определение освещённости поверхности зависит от угла между нормалью и источником света, который вычисляется через направляющие косинусы.
- **Навигация и робототехника**: описание ориентации объекта в пространстве.
